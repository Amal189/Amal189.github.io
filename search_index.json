[["index.html", "1 Welkom", " 1 Welkom Hoi! Welkom op mijn portfolio-website. Dit is de portfolio van Jasmijnbloem. Je bekijkt nu mijn GitHub-boek, waarin ik de opdrachten en resultaten van mijn leerproces laat zien. In deze portfolio vind je onder andere: Mijn cv (Curriculum Vitae) Een opdracht waarbij ik zelfstandig een nieuwe vaardigheid heb geleerd Data Management volgens Guerilla Analytics Reproduceerbare Analyse 1: C.-elegans toxiciteitsexperiment Reproduceerbare Analyse 2: Artikel beoordelen op reproduceerbaarheid Structured Query Language Zelf gemaakte R package Een geparametriseerd rapport over COVID-19 in Europa Introductie over MinION-project Referenties Veel plezier !  .. "],["curriculum-vitae.html", "2 Curriculum Vitae 2.1 Curriculum Vitae (Nederlands) 2.2 Curriculum Vitae (English Version)", " 2 Curriculum Vitae Dit document bevat mijn Curriculum Vitae (CV), opgesteld met RMarkdown. Het biedt een overzicht van de opleiding, werkervaring, vaardigheden (waaronder Data Science for Biology) en persoonlijke interesses. Het CV is bedoeld ter ondersteuning bij sollicitaties voor stageplekken of functies binnen de Life Sciences of bioinformatica. 2.1 Curriculum Vitae (Nederlands) Persoonlijke Gegevens Naam: [Jasmijbloem] E-mailadres: [Jasmijn.bloem@example.com] Telefoonnummer: [06-6666666] Opleiding Hogeschool Utrecht — BSc Biologie en Medisch Laboratoriumonderzoek 2022 – heden Derdejaarsstudent met een specialisatie in Biomolecular Research. Gedurende de opleiding zijn zowel theoretische kennis als praktische vaardigheden opgedaan in laboratoriumtechnieken, bioinformatica en data-analyse. Vaardigheden en Ervaring Technische en Analytische Vaardigheden - Eiwitonderzoek: Fluorescentie, UV-VIS spectrofotometrie, Bradford- en BCA-assays - Eiwitverwerking: SDS-PAGE, Western blotting, eiwitdigestie - Moleculaire technieken: ELISA, (q)PCR, gele-elektroforese, chromatografie - Sequencing: RNA-sequencing, MinION long-read sequencing, metagenomics - Data-analyse: RStudio, SQL, data management, datavisualisatie - Programmeren: Basis coderen, versiebeheer met GitHub - Bioinformatica: Werken met proteomics tools Persoonlijke Vaardigheden - Enthousiast - Leergierig - Spontaan - Hardwerkend - Gemotiveerd Onderzoekservaring Onderzoek naar het effect van protease op alfa-amylase tijdens de opleiding. Theoretische Basis Sterke achtergrond in moleculaire biologie, celbiologie en biotechnologie, opgedaan via diverse vakken binnen de opleiding. Talen Nederlands Engels Arabisch Interesses Zwemmen Schrijven Lezen 2.2 Curriculum Vitae (English Version) Personal Information Name: [Jasmijbloem] Email: [Jasmijn.bloem@example.com] Phone: [06-6666666] Education Hogeschool Utrecht (HU) — BSc in Biology and Medical Laboratory Research 2022 – present Third-year student specializing in Biomolecular Research. Throughout the program, both theoretical knowledge and practical skills have been developed in lab techniques, bioinformatics, and data analysis. Skills and Experience Technical and Analytical Skills - Protein Research: Fluorescence, UV-VIS spectrophotometry, Bradford and BCA assays - Protein Processing: SDS-PAGE, Western blotting, protein digestion - Molecular Techniques: ELISA, (q)PCR, gel electrophoresis, chromatography - Sequencing: RNA sequencing, MinION long-read sequencing, metagenomics - Data Analysis: RStudio, SQL, data management, data visualization - Programming: Basic coding, version control with GitHub - Bioinformatics: Proteomics tools Personal Skills - Enthusiastic - Eager to learn - Friendly and approachable - Hardworking - Highly motivated Research Experience Research on the effect of protease on alpha-amylase Theoretical Background Strong foundation in molecular biology, cell biology, and biotechnology, developed through coursework. Languages Dutch English Arabic Interests Swimming Writing Reading Credits Dit CV is opgesteld in RMarkdown met behulp van ideeën uit het rmarkdown-pakket van RStudio en voorbeelden van r-cv "],["vooruikijken-massaspectrometrie.html", "3 Vooruikijken: Massaspectrometrie 3.1 1. Toekomstbeeld en motivatie 3.2 2. Planning 3.3 3. Inleiding 3.4 4. Hoe ziet het systeem eruit? 3.5 Termen in de massaspectrometrie 3.6 Tools en packages 3.7 4. Uitwerking met msdata 3.8 5. Uitwerking met de pRolocdata 3.9 6. Zelf grafieken maken 3.10 Reflectie: 3.11 Bronnen", " 3 Vooruikijken: Massaspectrometrie Deze opdracht is onderdeel van de cursus Workflows en richt zich op het leren van een nieuwe Data Science for Biology skill: het analyseren van massaspectrometriedata in R. De keuze voor deze skill is gebaseerd op het toekomstbeeld waarin moleculair onderzoek gecombineerd wordt met bioinformatica. 3.1 1. Toekomstbeeld en motivatie Toekomstvisie Over een tot twee jaar mijn doel is om werkzaam te zijn in een onderzoeksomgeving zoals een academisch ziekenhuis, een universiteit of een biotechnologisch bedrijf. Het liefst in een rol waarin laboratoriumonderzoek wordt gecombineerd met bioinformatica, bijvoorbeeld op het gebied van eiwitonderzoek of medicijnontwikkeling. Huidige vaardigheden Praktische ervaring met laboratoriumtechnieken zoals eiwitanalyse, sequencing, PCR Data-analyse met R, GitHub en SQL Basiskennis van bioinformatica en datavisualisatie Nieuwe skill om te leren Om dichter bij het toekomstdoel te komen, wordt gekozen voor het leren analyseren van massaspectrometriedata. Deze analysetechniek is belangrijk in proteomics en wordt gebruikt voor eiwitidentificatie en -kwantificatie. Door dit te koppelen aan R wordt geleerd hoe ruwe data wordt omgezet naar bruikbare biologische informatie. Gekozen skill: Analyseren van massaspectrometriedata in R 3.2 2. Planning Datum Activiteit Tijd (uren) Toelichting 05 mei Introductie: wat is massaspectrometrie? 2 Begrijpen van het basisprincipe, zoeken van uitlegvideo’s 06 mei Wat kun je analyseren met massaspectrometrie? 2 Uitleg over toepassingen in eiwitonderzoek 07 mei Installeren van R-packages (MSnbase, Spectra) 2 R en Bioconductor gereedmaken 08 mei Tutorial volgen: voorbeeldanalyse bekijken 3 Gebruik maken van online tutorials 09 mei Begrippen oefenen: spectra, intensiteit, massa/charge 1 Leren herkennen in voorbeelddata 10 mei Voorbeelddataset downloaden (.mzML bestand) 2 Van PRIDE database of Bioconductor 11 mei Data inlezen in R 2 Gebruik maken van MSnbase::readMSData() 12 mei Eerste grafiek maken (bijv. chromatogram of spectrum) 3 Visualisatie oefenen met 1 sample 13 mei Meer samples toevoegen, data filteren of normaliseren 3 Werken aan kwaliteit van de data 14 mei Eenvoudige analyse uitvoeren 3 Bijvoorbeeld gemiddelde intensiteit per sample vergelijken 15 mei Resultaten visualiseren (boxplot, PCA of heatmap) 3 Overzicht maken van verschillen 16 mei Alles verwerken in RMarkdown 2 Duidelijk verslag maken van je leerproces 17 mei Uploaden naar GitHub 2 Resultaat delen als bewijs Totaal: 32 uur 3.3 3. Inleiding Massaspectrometrie is een krachtige techniek om moleculen zoals eiwitten te identificeren en kwantificeren op basis van hun massa en lading. In de proteomics wordt deze techniek veel gebruikt om eiwitprofielen van verschillende biologische condities te vergelijken, zoals zieke versus gezonde cellen. In deze opdracht leer ik hoe ik massaspectrometriedata kan analyseren met R en Bioconductor. Het doel is om inzicht te krijgen in de structuur van deze data, deze correct te visualiseren, te normaliseren en een eenvoudige statistische analyse uit te voeren. Doel: Het verwerven van basisvaardigheden in het analyseren van massaspectrometriedata met R, met behulp van publieke data en Bioconductor-tools. Figuur1: ILC mass spectrometers 3.4 4. Hoe ziet het systeem eruit? Wat is een massaspectrometer? Een massaspectrometer is een analytisch instrument dat moleculen meet op basis van hun massa en lading. Het bestaat uit drie hoofdonderdelen: 1. Inlaatsysteem (Ionisatiebron) In dit onderdeel wordt het monster omgezet in geladen deeltjes (ionen). Afhankelijk van het type monster en toepassing worden verschillende ionisatiemethoden gebruikt: Electrospray Ionization (ESI): zacht en geschikt voor eiwitten en peptiden in oplossing. Matrix-Assisted Laser Desorption/Ionization (MALDI): gebruikt voor grotere moleculen en vaste monsters. Electron Impact (EI): vooral gebruikt voor kleinere, vluchtige moleculen, bijvoorbeeld in GC-MS. Doel: moleculen omzetten in ionen zodat ze kunnen worden gemeten. 2. Analyser (Massascheider) De gevormde ionen worden gescheiden op basis van hun massa/lading-verhouding (m/z). Enkele veelgebruikte analyzers: Time-of-Flight (TOF): meet hoe snel ionen een afstand afleggen – lichtere ionen bewegen sneller. Quadrupole: gebruikt elektrische velden om specifieke m/z-waarden door te laten. Orbitrap / Ion Trap / FT-ICR: geavanceerde systemen met zeer hoge resolutie en nauwkeurigheid. Doel: scheiden van ionen op basis van m/z. 3. Detector De gescheiden ionen worden opgevangen door een detector, die hun aantal en m/z meet. Zo ontstaat een massaspectrum: een grafiek met m/z op de x-as en intensiteit op de y-as. Doel: meten van hoeveelheid ionen per m/z-waarde. Figuur 2:Hoe werkt massaspectrometrie Figuur 3: Componenten en typen massaspectrometers Wat kun je analyseren met massaspectrometrie? MS wordt breed ingezet in de biowetenschappen: Identificatie van eiwitten in biologische samples Kwantificatie van eiwitniveaus (labelvrij of met labels) Detectie van post-translationele modificaties (zoals fosforylatie) Analyse van biomarkers bij ziekte 3.5 Termen in de massaspectrometrie Belangrijke termen in de massaspectrometrie: Spectrum: een grafiek met pieken die ionen representeren. De intensiteit tegenover massa/lading (m/z) Mass-to-charge ratio (m/z): verhouding tussen massa en lading Intensiteit: hoogte van de piek – geeft hoeveelheid molecuul aan. In andere woorden hoe sterk het signaal is van een ion. De eenheid hiervan is meestal arbitrair en wordt vaak gewoon “intensiteit” genoemd. Het is een relatieve waarde die aangeeft hoe sterk het signaal is van de ionen, maar het is géén absolute concentratie in mol/liter of zo. Retention time: moment waarop het molecuul het systeem verlaat. In andere woorden tijd waarop een molecuul wordt gedetecteerd. Meestal uitgedrukt in seconden (s) of minuten (min). Voorbeeld van een chromatogram in R library(MSnbase) f &lt;- dir(system.file(&quot;sciex&quot;, package = &quot;msdata&quot;), full.names = TRUE)[1] ms_data &lt;- readMSData(f, mode = &quot;onDisk&quot;) chrom &lt;- chromatogram(ms_data) plot(chrom[1, 1], col = &quot;darkblue&quot;, lwd = 2) Figuur 4: Een voorbeeld van een chromatorgram in R. Op de y-as is de Intensiteit arbitraire eenheden (relatieve ionenintensiteit) en op de x-as is de retention time in seconden (s) te zien 3.6 Tools en packages Voor het analyseren van massaspectrometriedata in R zijn de volgende Bioconductor-packages nodig: # Installatie van benodigde packages if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(c(&quot;MSnbase&quot;, &quot;Spectra&quot;, &quot;pheatmap&quot;, &quot;ggplot2&quot;, &quot;FactoMineR&quot;, &quot;factoextra&quot;, &quot;Rtsne&quot;)) We gebruiken de volgende R-packages: # Laad de libraries die je nodig hebt voor de analyse. library(MSnbase) # Massaspectrometrie analyse library(Spectra) # Spectrum verwerking library(msdata) # Voorbeelddata voor massaspectrometrie library(ggplot2) # Grafieken maken library(pheatmap) # Heatmaps library(FactoMineR) # PCA-analyse library(factoextra) # Visualisatie PCA library(Rtsne) # t-SNE analyse library(tidyr) library(dplyr) 3.7 4. Uitwerking met msdata 3.7.1 Introductie bestandsformaat en voorbeelddata Voor deze opdracht gebruik ik een voorbeeldbestand uit het msdata-pakket van Bioconductor. Dit bestand heeft het .mzML-formaat, een open standaard voor massaspectrometrie (MS) data. Het .mzML-formaat is gebaseerd op XML en is gemaakt om ruwe MS-data goed en overzichtelijk op te slaan. Het werkt op verschillende computers en programma’s. In één bestand kunnen meerdere spectra zitten, bijvoorbeeld van verschillende MS-niveaus (zoals MS1 en MS2). Hierdoor kan ik ook ingewikkelde MS-experimenten analyseren, zoals experimenten met fragmentatie (MS/MS). 3.7.2 Hoe ik de data inlees Ik lees het voorbeeldbestand in met het readMSData-commando uit het MSnbase-pakket. Hierbij gebruik ik de optie onDisk, zodat ik niet alles tegelijk in het geheugen hoef te laden. Dit is handig, want MS-bestanden zijn vaak heel groot. Daarna bekijk ik een korte samenvatting van de data, zoals het aantal spectra, welke MS-niveaus aanwezig zijn, en de retentietijden (hoe lang het monster in de machine zat). # Het inlezen van een voorbeeld .mzML bestand uit het msdata-pakket. # Dit bestand bevat massaspectrometrie data in een open formaat. f &lt;- dir(system.file(&quot;sciex&quot;, package = &quot;msdata&quot;), full.names = TRUE)[1] # Lees het bestand in als OnDiskMSnExp object, dat efficiënt met grote data kan omgaan. ms_data &lt;- readMSData(f, mode = &quot;onDisk&quot;) # Toon een samenvatting van de data (aantal spectra, MS-levels, etc.) ms_data ## MSn experiment data (&quot;OnDiskMSnExp&quot;) ## Object size in memory: 0.36 Mb ## - - - Spectra data - - - ## MS level(s): 1 ## Number of spectra: 931 ## MSn retention times: 0:00 - 4:20 minutes ## - - - Processing information - - - ## Data loaded [Sun May 25 22:15:49 2025] ## MSnbase version: 2.32.0 ## - - - Meta data - - - ## phenoData ## rowNames: 20171016_POOL_POS_1_105-134.mzML ## varLabels: sampleNames ## varMetadata: labelDescription ## Loaded from: ## 20171016_POOL_POS_1_105-134.mzML ## protocolData: none ## featureData ## featureNames: F1.S001 F1.S002 ... F1.S931 (931 total) ## fvarLabels: fileIdx spIdx ... spectrum (35 total) ## fvarMetadata: labelDescription ## experimentData: use &#39;experimentData(object)&#39; 3.7.3 Verkennen van spectra Een veelgebruikte grafiek in massaspectrometrie is het chromatogram, bijvoorbeeld het Total Ion Chromatogram (TIC). Dit laat zien hoeveel ionen er per tijdspunt zijn gedetecteerd. Zo kan ik makkelijk zien waar pieken en mogelijke verstoringen zitten. # Check hoeveel spectra er in het bestand zitten. cat(&quot;Aantal spectra totaal:&quot;, length(ms_data), &quot;\\n&quot;) ## Aantal spectra totaal: 931 # Bekijk de verdeling van MS-niveaus (bijv. MS1, MS2) print(table(msLevel(ms_data))) ## ## 1 ## 931 # Bekijk het bereik van retentietijden (hoe lang duurde de meting) rt_range &lt;- range(rtime(ms_data)) cat(&quot;Retentietijd range:&quot;, rt_range[1], &quot;-&quot;, rt_range[2], &quot;seconden\\n&quot;) ## Retentietijd range: 0.28 - 259.757 seconden # Optioneel: histogram van retentietijden voor visuele inspectie hist(rtime(ms_data), breaks = 50, main = &quot;Histogram van retentietijden&quot;, xlab = &quot;Retentietijd (s)&quot;) Figuur 5: Een histogram van de retentietijden. Op de y-as is de frequency en op de x-as is de retentietijd in seconden (s) te zien 3.7.4 Plotten van chromatogram Met chromatogram() maak ik een Total Ion Chromatogram (TIC): # Maak een chromatogram aan, wat de totale ionenintensiteit over retentietijd weergeeft. chrom &lt;- chromatogram(ms_data) # Plot het eerste chromatogram (Total Ion Chromatogram) plot(chrom[1,1], col = &quot;darkblue&quot;, lwd = 2, main = &quot;Total Ion Chromatogram (TIC)&quot;) Figuur 6: Een chromatorgram. Op de y-as is de Intensiteit arbitraire eenheden (relatieve ionenintensiteit) en op de x-as is de retention time in seconden (s) te zien Het chromatogram geeft een overzicht van de totale intensiteit van ionen gedurende de looptijd van de meting. Dit kan pieken en afwijkingen laten zien. 3.7.5 Filteren op retentietijd en MS-level Vaak wil ik alleen de relevante data gebruiken. Daarom filter ik spectra op een bepaald retentietijd-interval en kies ik bijvoorbeeld alleen de MS1 spectra (de ‘precursor’ scans). Dit maakt de dataset kleiner en overzichtelijker, wat handig is voor verdere analyse. # Filter de spectra op een relevant retentietijd-interval, bijvoorbeeld het middenstuk van de run. rt_filter &lt;- c(rt_range[1] + 10, rt_range[2] - 10) ms_data_filtered &lt;- filterRt(ms_data, rt = rt_filter) # Beperk tot MS1 spectra (eerste niveau massaspectrometrie) ms_data_filtered &lt;- filterMsLevel(ms_data_filtered, msLevel = 1) cat(&quot;Aantal spectra na filteren:&quot;, length(ms_data_filtered), &quot;\\n&quot;) ## Aantal spectra na filteren: 859 if(length(ms_data_filtered) == 0) stop(&quot;Geen spectra gevonden na filteren! Pas je RT interval aan.&quot;) 3.7.6 Gemiddeld spectrum handmatig berekenen en plotten Door meerdere spectra samen te voegen kan ik een gemiddeld spectrum maken. Dit helpt om ruis te verminderen en algemene pieken beter te herkennen. Ik pak alle spectra, zet de m/z-waarden om naar een gemeenschappelijk raster, interpolateer de intensiteiten en bereken het gemiddelde per m/z-waarde. Daarna plot ik het gemiddelde spectrum. # Haal individuele spectra op uit het gefilterde object spectra_list &lt;- spectra(ms_data_filtered) # Pak m/z waarden en intensiteiten per spectrum mz_list &lt;- lapply(spectra_list, mz) int_list &lt;- lapply(spectra_list, intensity) # Combineer alle m/z waarden voor een gemeenschappelijk raster mz_vals_all &lt;- unlist(mz_list) mz_vals_all &lt;- mz_vals_all[is.finite(mz_vals_all)] if(length(mz_vals_all) == 0) stop(&quot;Geen valide m/z waarden gevonden!&quot;) # Definieer gemeenschappelijk m/z raster met stapgrootte 0.1 common_mz &lt;- seq(from = min(mz_vals_all), to = max(mz_vals_all), by = 0.1) # Functie om intensiteiten te interpoleren naar het gemeenschappelijke raster interp_intensity &lt;- function(mz_vals, intensities, common_mz) { approx(mz_vals, intensities, xout = common_mz, yleft = 0, yright = 0)$y } # Interpoleer alle spectra naar hetzelfde m/z raster interp_intensities &lt;- sapply(seq_along(mz_list), function(i) { interp_intensity(mz_list[[i]], int_list[[i]], common_mz) }) # Bereken het gemiddelde spectrum mean_intensity &lt;- rowMeans(interp_intensities) # Plot het gemiddelde spectrum plot(common_mz, mean_intensity, type = &quot;l&quot;, xlab = &quot;m/z&quot;, ylab = &quot;Gemiddelde intensiteit&quot;, main = &quot;Gemiddeld spectrum (handmatig berekend)&quot;) Figuur 7: Een gemiddeld spectrum (handmatig berekend). Op de y-as is de gemiddelde Intensiteit arbitraire eenheden (relatieve ionenintensiteit) en op de x-as is de Mass-to-charge ratio (m/z) te zien 3.7.7 PCA op voorbeelddata Met Principal Component Analysis (PCA) kan ik patronen en verschillen tussen spectra ontdekken. PCA maakt ingewikkelde data eenvoudiger door ze samen te vatten in een paar belangrijke componenten. Ik gebruik een deel van de spectra om PCA uit te voeren en plot het resultaat. Zo kan ik zien welke spectra op elkaar lijken en welke verschillen, wat kan wijzen op verschillende monsters of condities. PCA helpt mij om de complexiteit van de data te verminderen en te zien of spectra in groepen clusteren of juist veel variatie laten zien. # Gebruik een subset van spectra (maximaal 50) voor PCA vanwege rekentijd n_pca &lt;- min(50, length(ms_data_filtered)) intensity_mat &lt;- interp_intensities[, 1:n_pca] # Transponeer zodat spectra rijen zijn en m/z kolommen intensity_mat_t &lt;- t(intensity_mat) # Voer PCA uit om patronen en clustering te vinden pca_res &lt;- PCA(intensity_mat_t, graph = FALSE) # Visualiseer PCA-resultaten fviz_pca_ind(pca_res, title = &quot;PCA van massaspectrometriedata&quot;) Figuur 8: PCA-plot waarin spectra worden weergegeven op basis van de belangrijkste variaties in de data. De assen tonen de eerste twee principal components, die samenvattingen zijn van de verschillen tussen spectra. Deze PCA-plot toont de eerste twee hoofdcomponenten van de massaspectrometriedata, die samen 8% van de totale variatie verklaren. Elk punt vertegenwoordigt een spectrum; spectra die dicht bij elkaar liggen, vertonen gelijkaardige signaalpatronen, terwijl uitbijters (zoals punt 6 en 30) mogelijk afwijkende profielen hebben. De lage verklaarde variantie wijst op complexe data met veel dimensies. Deze visualisatie geeft een eerste indruk van gelijkenissen en verschillen tussen spectra. 3.7.8 t-SNE visualisatie van spectra Waar PCA lineaire verbanden tussen spectra onderzoekt, is t-distributed Stochastic Neighbor Embedding (t-SNE) een niet-lineaire methode die speciaal geschikt is om lokale structuur en clusters in hoge-dimensionale data zichtbaar te maken. t-SNE reduceert de data tot twee dimensies, zodat ik de verschillen tussen spectra kan visualiseren in een scatterplot. Dit helpt mij om bijvoorbeeld subtiele verschillen tussen spectra op te sporen die in PCA minder duidelijk zichtbaar zijn. # t-SNE vereist volledige data zonder ontbrekende waarden if (any(!is.finite(intensity_mat_t))) { warning(&quot;Niet alle waarden zijn eindig. Vervang NA/Inf met 0 voor t-SNE.&quot;) intensity_mat_t[!is.finite(intensity_mat_t)] &lt;- 0 } # t-SNE analyse uitvoeren (dit kan enige tijd duren) set.seed(123) # Voor reproduceerbaarheid tsne_res &lt;- Rtsne(intensity_mat_t, dims = 2, perplexity = 10, verbose = TRUE) ## Performing PCA ## Read the 50 x 50 data matrix successfully! ## OpenMP is working. 1 threads. ## Using no_dims = 2, perplexity = 10.000000, and theta = 0.500000 ## Computing input similarities... ## Building tree... ## Done in 0.00 seconds (sparsity = 0.737600)! ## Learning embedding... ## Iteration 50: error is 54.405711 (50 iterations in 0.00 seconds) ## Iteration 100: error is 57.432260 (50 iterations in 0.00 seconds) ## Iteration 150: error is 55.561156 (50 iterations in 0.00 seconds) ## Iteration 200: error is 60.018003 (50 iterations in 0.00 seconds) ## Iteration 250: error is 58.704198 (50 iterations in 0.00 seconds) ## Iteration 300: error is 1.880032 (50 iterations in 0.00 seconds) ## Iteration 350: error is 1.471422 (50 iterations in 0.00 seconds) ## Iteration 400: error is 0.885947 (50 iterations in 0.00 seconds) ## Iteration 450: error is 0.818365 (50 iterations in 0.00 seconds) ## Iteration 500: error is 0.646077 (50 iterations in 0.00 seconds) ## Iteration 550: error is 0.450060 (50 iterations in 0.00 seconds) ## Iteration 600: error is 0.428152 (50 iterations in 0.00 seconds) ## Iteration 650: error is 0.426304 (50 iterations in 0.00 seconds) ## Iteration 700: error is 0.425267 (50 iterations in 0.00 seconds) ## Iteration 750: error is 0.423981 (50 iterations in 0.00 seconds) ## Iteration 800: error is 0.422391 (50 iterations in 0.00 seconds) ## Iteration 850: error is 0.420444 (50 iterations in 0.00 seconds) ## Iteration 900: error is 0.424439 (50 iterations in 0.00 seconds) ## Iteration 950: error is 0.424924 (50 iterations in 0.00 seconds) ## Iteration 1000: error is 0.408937 (50 iterations in 0.00 seconds) ## Fitting performed in 0.03 seconds. # Resultaten in een dataframe voor ggplot tsne_df &lt;- data.frame( Dim1 = tsne_res$Y[,1], Dim2 = tsne_res$Y[,2], Spectrum = factor(1:nrow(tsne_res$Y)) ) # Plot met ggplot2 ggplot(tsne_df, aes(x = Dim1, y = Dim2)) + geom_point(color = &quot;darkred&quot;, size = 2) + theme_minimal() + labs(title = &quot;t-SNE visualisatie van spectra&quot;, x = &quot;t-SNE Dimensie 1&quot;, y = &quot;t-SNE Dimensie 2&quot;) Figuur 9: t-SNE-plot van de spectrale data. Elk punt stelt een spectrum voor. Nabijheid in de plot suggereert gelijkaardige piekpatronen. De methode is gevoelig voor lokale structuren in de data. Deze t-SNE plot laat zien hoe massaspectra zich groeperen. Ik zie duidelijke clusters: spectra die chemisch op elkaar lijken, liggen dicht bij elkaar. De lege ruimtes tussen clusters tonen duidelijke verschillen tussen groepen. Compacte clusters betekenen sterke overeenkomsten, verspreide punten zijn mogelijk uitschieters. Deze visualisatie helpt me snel patronen en relaties te herkennen. 3.8 5. Uitwerking met de pRolocdata In deze analyse gebruik ik massaspectrometriegegevens uit de dunkley2006 dataset, die beschikbaar is via het pRolocdata-pakket. Deze dataset bevat kwantitatieve gegevens over eiwitten in plantencellen en hun lokalisatie in verschillende subcellulaire compartimenten. Met behulp van PCA, t-SNE en machine learning (SVM) onderzoek ik hoe goed eiwitten op basis van deze data geclassificeerd kunnen worden naar hun locatie in de cel. 3.8.1 Stap 1: Installatie en laden van benodigde pakketten Voor deze analyse heb ik de volgende R/Bioconductor-pakketten nodig: pRoloc en pRolocdata: voor data en analyse van eiwitlokalisatie. Rtsne: om t-SNE plots te maken. pheatmap: om expressiedata te visualiseren in een heatmap. # Installeer Bioconductor-pakketten als ze nog niet aanwezig zijn if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) # Installeer benodigde pakketten BiocManager::install(c(&quot;pRoloc&quot;, &quot;pRolocdata&quot;, &quot;Rtsne&quot;, &quot;pheatmap&quot;)) # Nu laad ik de pakketten: library(pRoloc) library(pRolocdata) library(Rtsne) library(pheatmap) 3.8.2 Stap 2: Laad de dunkley2006 dataset Ik laad de dunkley2006 dataset. Deze bevat een MSnSet object met eiwitexpressies over meerdere fracties. data(dunkley2006) dunkley2006 # Toont samenvatting van het MSnSet object ## MSnSet (storageMode: lockedEnvironment) ## assayData: 689 features, 16 samples ## element names: exprs ## protocolData: none ## phenoData ## sampleNames: M1F1A M1F4A ... M2F11B (16 total) ## varLabels: membrane.prep fraction replicate ## varMetadata: labelDescription ## featureData ## featureNames: AT1G09210 AT1G21750 ... AT4G39080 (689 total) ## fvarLabels: assigned evidence ... markers (8 total) ## fvarMetadata: labelDescription ## experimentData: use &#39;experimentData(object)&#39; ## pubMedIds: 16618929 ## Annotation: ## - - - Processing information - - - ## Loaded on Thu Jul 16 22:53:08 2015. ## Normalised to sum of intensities. ## Added markers from &#39;mrk&#39; marker vector. Thu Jul 16 22:53:08 2015 ## MSnbase version: 1.17.12 3.8.3 Stap 3: Eerste verkenning van de dataset Ik begin met het verkennen van de structuur van de data: # Dimensies: aantal eiwitten (features) × aantal metingen (samples) dim(dunkley2006) ## [1] 689 16 # Bekijk de eerste paar rijen van de eiwit-annotaties (featureData) head(fData(dunkley2006)) ## assigned evidence method new pd.2013 pd.markers markers.orig ## AT1G09210 ER predicted PLSDA known ER ER lumen ER ## AT1G21750 ER predicted PLSDA known ER ER lumen ER ## AT1G51760 ER unknown PLSDA new ER ER lumen unknown ## AT1G56340 ER predicted PLSDA known ER ER lumen ER ## AT2G32920 ER predicted PLSDA known ER ER lumen ER ## AT2G47470 ER predicted PLSDA known ER ER lumen ER ## markers ## AT1G09210 ER lumen ## AT1G21750 ER lumen ## AT1G51760 ER lumen ## AT1G56340 ER lumen ## AT2G32920 ER lumen ## AT2G47470 ER lumen # Bekijk hoeveel eiwitten zijn gelabeld per subcellulaire locatie table(fData(dunkley2006)$markers) ## ## ER lumen ER membrane Golgi Mitochondrion Plastid ## 14 45 28 55 20 ## PM Ribosome TGN unknown vacuole ## 46 19 13 428 21 Er zijn honderden eiwitten en een aantal daarvan zijn al gelabeld met bekende subcellulaire locaties, wat nuttig is voor supervised learning. 3.8.4 Stap 4: PCA-plot van eiwitexpressie Met Principal Component Analysis (PCA) reduceer ik de dimensies van de dataset zodat ik de clusters van eiwitten kan visualiseren. # Genereer een PCA-plot waarbij de eiwitten gekleurd zijn volgens hun &#39;marker&#39; label plot2D(dunkley2006, method = &quot;PCA&quot;, fcol = &quot;markers&quot;) Figuur 10: PCA-plot van eiwitexpressie uit dunkley2006 dataset. De assen tonen de eerste twee principal components, die samenvattingen zijn van de verschillen tussen spectra. In de PCA-plot zie ik duidelijk clustering van eiwitten met dezelfde subcellulaire lokalisatie, wat erop wijst dat de data geschikt is voor classificatie. 3.8.5 Stap 5: t-SNE voor niet-lineaire visualisatie Met t-SNE kan ik expressiedata visualiseren op een manier die niet-lineaire patronen beter laat zien dan PCA. Dit kan leiden tot duidelijkere clusters. # Zet een seed voor reproduceerbare resultaten set.seed(123) # Bereken t-SNE met een perplexity-waarde van 30 tsne_res &lt;- Rtsne(exprs(dunkley2006), perplexity = 30) # Plot de t-SNE resultaten en kleur de eiwitten op basis van hun marker plot(tsne_res$Y, col = as.factor(fData(dunkley2006)$markers), pch = 19, main = &quot;t-SNE: eiwitlokalisatie&quot;, xlab = &quot;t-SNE 1&quot;, ylab = &quot;t-SNE 2&quot;) # Voeg een legenda toe legend(&quot;topright&quot;, legend = levels(factor(fData(dunkley2006)$markers)), col = 1:length(unique(fData(dunkley2006)$markers)), pch = 19) Figuur 11 : t-SNE-plot van de dunkley2006 dataset. Elk punt stelt een spectrum voor. Nabijheid in de plot suggereert gelijkaardige piekpatronen. De methode is gevoelig voor lokale structuren in de data. De t-SNE plot laat zien dat veel eiwitten met dezelfde lokalisatie bij elkaar gegroepeerd worden in 2D-ruimte. 3.8.6 Stap 6: Heatmap van eiwitexpressie Om een overzicht te krijgen van de expressie van de eerste 50 eiwitten, maak ik een heatmap. # Genereer een heatmap van de expressie van de eerste 50 eiwitten pheatmap(exprs(dunkley2006)[1:50, ], show_rownames = FALSE, main = &quot;Expressie heatmap van eerste 50 eiwitten&quot;) Figuur 11: Een heatmap met de dunkley2006 dataset. De heatmap helpt bij het visualiseren van patronen in expressie over de verschillende fractionele metingen. 3.9 6. Zelf grafieken maken Aller laatst heb ik geprobeerd zelf een gemiddeld massaspectrumspectrum en chromatogram te maken zonder datasets of packages te gebruiken. set.seed(42) # Simuleer massa (m/z) waarden mz_values &lt;- seq(400, 1600, by = 1) # Simuleer intensiteiten met enkele pieken intensities &lt;- dnorm(mz_values, mean = 700, sd = 20) * 100 + dnorm(mz_values, mean = 900, sd = 15) * 150 + dnorm(mz_values, mean = 1200, sd = 30) * 70 + rnorm(length(mz_values), mean = 5, sd = 2) plot(mz_values, intensities, type = &quot;l&quot;, col = &quot;blue&quot;, xlab = &quot;m/z (massa/charge)&quot;, ylab = &quot;Intensiteit&quot;, main = &quot;Gemiddeld spectrum&quot;) Figuur 12: Gemiddeld massaspectrumspectrum met pieken bij verschillende massa’s. # Simuleer retentietijden (minuten) rt_values &lt;- seq(0, 30, length.out = 100) # Simuleer intensiteit met enkele pieken in retentietijd intensity_rt &lt;- dnorm(rt_values, mean = 10, sd = 1.5) * 1000 + dnorm(rt_values, mean = 18, sd = 2) * 1200 + dnorm(rt_values, mean = 25, sd = 1) * 900 + rnorm(length(rt_values), mean = 100, sd = 30) plot(rt_values, intensity_rt, type = &quot;l&quot;, col = &quot;darkgreen&quot;, xlab = &quot;Retentietijd (minuten)&quot;, ylab = &quot;Intensiteit&quot;, main = &quot;Gemiddeld chromatogram&quot;) Figuur 13: Een chromatorgram. Op de y-as is de Intensiteit arbitraire eenheden (relatieve ionenintensiteit) en op de x-as is de retention time in seconden (s) te zien 3.10 Reflectie: Voor deze vrije ruimte opdracht heb ik eerst een technische workshop gevolgd van ongeveer vier uur. Tijdens die workshop heb ik de massaspectrometer in het echt gezien en een experiment ermee uitgevoerd. Voorafgaand aan de workshop heb ik mezelf goed voorbereid door uitlegvideo’s over massaspectrometrie te bekijken. Deze voorbereiding, samen met de workshop, heeft mij in totaal ongeveer tien uur studie opgeleverd. Het moeilijkste onderdeel was het vinden en bestuderen van geschikte R-pakketten om massaspectrometrie-data te analyseren, en tegelijkertijd te proberen te werken met een eenvoudige dataset. Dit heeft mij veel tijd gekost, ongeveer vijftien uur. De laatste vijf uur heb ik extra analyses geprobeerd te doen op een andere dataset, maar het was vaak lastig om geschikte open data te vinden voor massaspectrometrie. Sommige bestanden waren beschadigd of moeilijk leesbaar, waardoor ik ze niet kon gebruiken. Daarom heb ik uiteindelijk gekozen om een eenvoudige dataset te gebruiken die direct beschikbaar is in R, zoals die uit het pRolocdata-pakket. Daarnaast heb ik onderzocht welke mogelijkheden er zijn om in de toekomst verdere analyses te proberen en welke data beter geschikt kunnen zijn. 3.11 Bronnen Gatto, L., &amp; Lilley, K. S. (2012). MSnbase - an R/Bioconductor package for isobaric tagged mass spectrometry data visualization, processing and quantitation. Bioinformatics, 28(2), 288–289. https://doi.org/10.1093/bioinformatics/btr645 Bioconductor project. MSnbase. Geraadpleegd via: https://bioconductor.org/packages/MSnbase Bioconductor project. Spectra. Geraadpleegd via: https://bioconductor.org/packages/Spectra Bioconductor project. msdata. Geraadpleegd via: https://bioconductor.org/packages/msdata Tyanova, S., Temu, T., &amp; Cox, J. (2016). The MaxQuant computational platform for mass spectrometry–based shotgun proteomics. Nature Protocols, 11(12), 2301–2319. https://doi.org/10.1038/nprot.2016.136 ProteomeXchange Consortium. PRIDE database. Geraadpleegd via: https://www.ebi.ac.uk/pride/ Wikipedia contributors. (2024). Mass spectrometry. In Wikipedia, The Free Encyclopedia. Geraadpleegd op 24 mei 2025, van https://en.wikipedia.org/wiki/Mass_spectrometry StackOverflow. Diverse antwoorden over gebruik van MSnbase en Spectra-pakketten in R. Geraadpleegd tussen mei 2024 en mei 2025. Tutorials van Bioconductor: Introduction to MSnbase and Spectra. Geraadpleegd via: https://rdrr.io/bioc/MSnbase/f/vignettes/v01-MSnbase-demo.Rmd Hogeschool Utrecht. (2025). Figuur 1 t/m 3 afkomstig uit de cursus Projecticum Biomolecular Research, semester 5, Blok C – Tech-workshop G: Mass spectrometry. Geraadpleegd op 24 mei 2025 van: https://canvas.hu.nl/courses/44565/pages/tech-workshop-g-mass-spectrometry Dit rapport is tot stand gekomen met hulp van ChatGPT (OpenAI). Het schrijven van de codes bij sommige stukjes was zonder deze ondersteuning erg lastig. "],["guerilla-analytics.html", "4 Guerilla analytics 4.1 DAUR2_RNAseq 4.2 Portfolio van Jasmijnbloem 4.3 Referentie", " 4 Guerilla analytics Data Management volgens Guerilla Analytics In dit stukje werden de richtlijnen van Guerilla Analytics toegepast. Guerilla Analytics is een werkwijze voor datamanagement die zich richt op praktisch, flexibel en reproduceerbaar werken met data, vooral in snel veranderende of tijdelijke projecten. De kernprincipes zijn: Heldere mapstructuur: Bestanden worden logisch gescheiden in mappen zoals raw_data, data, analyses en results. Nooit wijzigen van ruwe data: De originele bestanden blijven altijd intact. Script-based workflows: Analyses worden in scripts opgeslagen om reproduceerbaarheid te geven. Transparante documentatie: Er is een README-bestand dat uitlegt wat elk bestand en elke map bevat. Snel overdraagbaar: De structuur maakt het makkelijk voor anderen om het project over te nemen of na te bouwen. Voor deze opdracht werden lege bestanden gebruikt met de juiste namen en een mappenstructuur opgezet volgens deze regels, ook al de originele data niet beschikbaar was. 4.1 DAUR2_RNAseq De mapstructuur van dit project heb ik opgebouwd met de volgende code: # Laat de structuur van de DAUR2_RNAseq-map zien. fs::dir_tree(&quot;DAUR2_RNAseq&quot;)` De verkregen FASTQ-bestanden (de ruwe data) zijn geplaatst in de map raw_data. In de map data bevinden zich twee submappen: - alignment, waarin de BAM-bestanden staan met de gemapte reads - counts, waarin de gen-tellingen en de metadata van de samples zijn opgeslagen. In de map analyses staan de scripts die zijn gebruikt voor de verwerking en analyse van de data. De map results bevat de output van deze analyses, zoals grafieken en kwaliteitsrapporten. Tot slot is er een map verslag waarin het verslag van deze opdracht is opgenomen als .Rmd-bestand, samen met het bijbehorende .html-bestand (Figuur 1). Figuur 1:Mapstructuur screenshot van DAUR2 RNA sequencing project Daarnaast werd in de README-bestand uitlegt wat elk bestand en elke map bevat (Figuur 2). Figuur 2:README screenshot van DAUR2 RNA sequencing project 4.2 Portfolio van Jasmijnbloem Het is onmogelijk om een volledige screenshot te maken van mijn portfolio-bestand vanwege de omvang. Daarom heb ik ervoor gekozen om de mapstructuur direct vanuit de code te tonen: fs::dir_tree() ## . ## ├── 01_CV.Rmd ## ├── 02_Vooruitkijken.Rmd ## ├── 04_Guerilla_analytics.Rmd ## ├── 05_C.-elegans_toxiciteitsexperiment.Rmd ## ├── 06_artikel_beoordelen.Rmd ## ├── 07_Structured_Query_Language.Rmd ## ├── 08_R_package.Rmd ## ├── 09_Geparametrizeerde_Rmarkdown.Rmd ## ├── 10_Project_intro.Rmd ## ├── data ## │ ├── dengue_avg.csv ## │ ├── flu_avg.csv ## │ ├── gapminder.csv ## │ └── joined_data.csv ## ├── dsfb2_workflows_portfolio_Amal2.Rproj ## ├── figs ## │ ├── Componenten_en_typen_massaspectrometers.png ## │ ├── GenExpressie.png ## │ ├── How_works_MS_1.png ## │ ├── Jasmijnbloem.png ## │ ├── mapstructuur_RNAseq.png ## │ ├── Massa.png ## │ ├── Readme_portfolio1.png ## │ ├── Readme_portfolio2.png ## │ └── readme_screenshot_RNAseq.png ## ├── index.Rmd ## ├── LICENSE ## ├── raw_data ## │ ├── CE.LIQ.FLOW.062_Tidydata.xlsx ## │ ├── COVID_19.xlsx ## │ ├── dengue_data.csv ## │ └── flu_data.csv ## ├── README.md ## ├── referenties.bib ## ├── Style.css ## ├── _book ## │ ├── 01_CV.Rmd ## │ ├── 02_Vooruitkijken.Rmd ## │ ├── 04_Guerilla_analytics.Rmd ## │ ├── 05_C.-elegans_toxiciteitsexperiment.Rmd ## │ ├── 06_artikel_beoordelen.Rmd ## │ ├── 07_Structured_Query_Language.Rmd ## │ ├── 08_R_package.Rmd ## │ ├── 10_Project_intro.Rmd ## │ ├── 404.html ## │ ├── c.elegans-toxiciteitsexperiment.html ## │ ├── curriculum-vitae.html ## │ ├── cv.html ## │ ├── data-managment.html ## │ ├── figs ## │ │ ├── Componenten_en_typen_massaspectrometers.png ## │ │ ├── GenExpressie.png ## │ │ ├── How_works_MS_1.png ## │ │ ├── Jasmijnbloem.png ## │ │ ├── mapstructuur_RNAseq.png ## │ │ ├── Massa.png ## │ │ ├── Readme_portfolio1.png ## │ │ ├── Readme_portfolio2.png ## │ │ └── readme_screenshot_RNAseq.png ## │ ├── GenExpressie.png ## │ ├── geparameteriseerd-covid-19-europa-rapport.html ## │ ├── geparameteriseerd-covid-19-rapport.html ## │ ├── geparametriseerd-covid-19-rapport.html ## │ ├── guerilla-analytics.html ## │ ├── index.html ## │ ├── Jasmijnbloem.png ## │ ├── libs ## │ │ ├── anchor-sections-1.1.0 ## │ │ │ ├── anchor-sections-hash.css ## │ │ │ ├── anchor-sections.css ## │ │ │ └── anchor-sections.js ## │ │ ├── core-js-2.5.3 ## │ │ │ └── shim.min.js ## │ │ ├── gitbook-2.6.7 ## │ │ │ ├── css ## │ │ │ │ ├── fontawesome ## │ │ │ │ │ └── fontawesome-webfont.ttf ## │ │ │ │ ├── plugin-bookdown.css ## │ │ │ │ ├── plugin-clipboard.css ## │ │ │ │ ├── plugin-fontsettings.css ## │ │ │ │ ├── plugin-highlight.css ## │ │ │ │ ├── plugin-search.css ## │ │ │ │ ├── plugin-table.css ## │ │ │ │ └── style.css ## │ │ │ └── js ## │ │ │ ├── app.min.js ## │ │ │ ├── clipboard.min.js ## │ │ │ ├── jquery.highlight.js ## │ │ │ ├── plugin-bookdown.js ## │ │ │ ├── plugin-clipboard.js ## │ │ │ ├── plugin-fontsettings.js ## │ │ │ ├── plugin-search.js ## │ │ │ └── plugin-sharing.js ## │ │ ├── htmltools-fill-0.5.8.1 ## │ │ │ └── fill.css ## │ │ ├── htmlwidgets-1.6.4 ## │ │ │ └── htmlwidgets.js ## │ │ ├── jquery-3.6.0 ## │ │ │ └── jquery-3.6.0.min.js ## │ │ ├── react-18.2.0 ## │ │ │ ├── react-dom.min.js ## │ │ │ └── react.min.js ## │ │ ├── reactable-0.4.4 ## │ │ │ └── reactable.css ## │ │ ├── reactable-binding-0.4.4 ## │ │ │ └── reactable.js ## │ │ └── reactwidget-2.0.0 ## │ │ └── react-tools.js ## │ ├── mapstructuur.png ## │ ├── mapstructuur_RNAseq.png ## │ ├── project-introductie.html ## │ ├── r-package.html ## │ ├── readme_screenshot.png ## │ ├── readme_screenshot_RNAseq.png ## │ ├── referenties.bib ## │ ├── referenties.html ## │ ├── reproduceerbare-analyse-1.html ## │ ├── reproduceerbare-analyse-2-artikel-beoordelen-op-reproduceerbaarheid.html ## │ ├── reproduceerbare-analyse-2.html ## │ ├── reproduceerbare-analyse-van-c.-elegans-data.html ## │ ├── reproduceerbare-analyse.html ## │ ├── samenvatting-in-tabelvorm.html ## │ ├── search_index.json ## │ ├── stap-2-download-en-verwerk-de-data.html ## │ ├── structured-query-language.html ## │ ├── style.css ## │ ├── vooruikijken-massaspectrometrie.html ## │ ├── vrij-ruimte.html ## │ ├── _book ## │ │ ├── c.elegans-toxiciteitsexperiment.html ## │ │ ├── curriculum-vitae.html ## │ │ ├── geparameteriseerd-covid-19-rapport.html ## │ │ ├── guerilla-analytics.html ## │ │ ├── project-introductie.html ## │ │ ├── r-package.html ## │ │ ├── referenties.html ## │ │ ├── reproduceerbare-analyse-2-artikel-beoordelen-op-reproduceerbaarheid.html ## │ │ ├── structured-query-language.html ## │ │ └── vrij-ruimte.html ## │ └── _main_files ## │ └── figure-html ## │ ├── bb-1.png ## │ ├── breken-1.png ## │ ├── chroom-1.png ## │ ├── corr-1.png ## │ ├── COVID-1.png ## │ ├── decane-1.png ## │ ├── diii-1.png ## │ ├── dosis-1.png ## │ ├── dosis3-1.png ## │ ├── dosisss-1.png ## │ ├── dosisss-2.png ## │ ├── dosisss-3.png ## │ ├── dosisss-4.png ## │ ├── ethanol-1.png ## │ ├── explore-ms-1.png ## │ ├── heatma-1.png ## │ ├── joined-1.png ## │ ├── lijnen-1.png ## │ ├── lijnplot-1.png ## │ ├── mappp-1.png ## │ ├── mean-spectrum-1.png ## │ ├── naphtalene-1.png ## │ ├── pca plot-1.png ## │ ├── pca plot22-1.png ## │ ├── pca-1.png ## │ ├── plot-chrom-1.png ## │ ├── plot-chromatogram-1.png ## │ ├── quiz4-1.png ## │ ├── quiz5-1.png ## │ ├── scatterplot-1.png ## │ ├── scatterplottwee-1.png ## │ ├── spectrum-1.png ## │ ├── t-SNE-1.png ## │ ├── tE-1.png ## │ ├── unnamed-chunk-1-1.png ## │ ├── unnamed-chunk-2-1.png ## │ └── voorstel-1.png ## ├── _bookdown_files ## ├── _main.Rmd ## └── _main_files ## └── figure-html ## ├── bb-1.png ## ├── breken-1.png ## ├── chroom-1.png ## ├── corr-1.png ## ├── COVID-1.png ## ├── decane-1.png ## ├── diii-1.png ## ├── dosis3-1.png ## ├── ethanol-1.png ## ├── explore-ms-1.png ## ├── heatma-1.png ## ├── joined-1.png ## ├── lijnen-1.png ## ├── lijnplot-1.png ## ├── mappp-1.png ## ├── mean-spectrum-1.png ## ├── naphtalene-1.png ## ├── pca plot-1.png ## ├── pca plot22-1.png ## ├── pca-1.png ## ├── plot-chrom-1.png ## ├── plot-chromatogram-1.png ## ├── quiz4-1.png ## ├── quiz5-1.png ## ├── scatterplot-1.png ## ├── scatterplottwee-1.png ## ├── spectrum-1.png ## ├── t-SNE-1.png ## ├── tE-1.png ## ├── unnamed-chunk-1-1.png ## └── unnamed-chunk-2-1.png Figuur 3: Mapstructuur van mijn portfolio. Deze mapstructuur geeft een overzicht van alle belangrijke bestanden en mappen binnen mijn project. Dit helpt om snel inzicht te krijgen in de opbouw en inhoud van het portfolio. De RMarkdown-bestanden (.Rmd) bevatten verschillende onderdelen van mijn portfolio, waaronder: Mijn persoonlijke CV (01_CV.Rmd) Vooruitblik op mijn toekomstige vaardigheden en leerdoelen (02_Vooruitkijken.Rmd) Analyses en visualisaties van biologische data, zoals een toxiciteitsexperiment met C. elegans (05_C.-elegans_toxiciteitsexperiment.Rmd) Een beoordeling van wetenschappelijke artikelen op reproduceerbaarheid (06_artikel_beoordelen.Rmd) Een introductie en toepassing van gestructureerde querytalen in data-analyse (07_Structured_Query_Language.Rmd) Het maken van een eigen R-package als project (08_R_package.Rmd) Geparametriseerde RMarkdown-rapporten, bijvoorbeeld voor COVID-19 data (09_Geparametrizeerde_Rmarkdown.Rmd) En een algemene projectintroductie (10_Project_intro.Rmd) Daarnaast wordt in het README-bestand per bestand en map uitgelegd wat de inhoud en het doel ervan is (zie Figuur 4 en 5). Zo kan iedereen die het project bekijkt eenvoudig begrijpen welke analyses, data en documenten waar te vinden zijn. Figuur 4:README screenshot 1 van mijn portfolio Figuur 5:README screenshot 2 van mijn portfolio 4.3 Referentie Ridge, E. (2014). Guerrilla Analytics: A Practical Approach to Working with Data. Morgan Kaufmann. Guerrilla Analytics. (z.d.). The Principles. Geraadpleegd op 25 mei 2025, van https://guerrilla-analytics.net/the-principles Guerrilla Analytics: een kort overzicht. (n.d.). Geraadpleegd op 25 mei 2025, van https://dataschool.nl/kennis/guerrilla-analytics/ "],["reproduceerbare-analyse-1.html", "5 Reproduceerbare Analyse 1 5.1 C.elegans toxiciteitsexperiment 5.2 Stappenplan voor dose-response analyse 5.3 Wetenschappelijke Referenties", " 5 Reproduceerbare Analyse 1 5.1 C.elegans toxiciteitsexperiment In dit hoofdstuk wordt een analyse uitgevoerd op data uit een C. elegans-experiment. Tijdens dit experiment werden nematoden van de soort Caenorhabditis elegans blootgesteld aan verschillende concentraties van een aantal chemicaliën. De geteste stoffen zijn: 2,6-diisopropylnaphthalene, decaan, naftaleen, ethanol en S-medium. Voor de analyse zijn de volgende variabelen in de dataset relevant: RawData: het aantal nakomelingen dat is geteld per conditie. compName: de naam van het chemicalie waaraan de wormen zijn blootgesteld. compConcentration: de concentratie van het gebruikte chemicalie. expType: een aanduiding of het gaat om een experimentele conditie of een controle (negatieve controle of vehiclecontrole). De dataset is afkomstig van het HU-lectoraat Innovative Testing in Life Sciences &amp; Chemistry. Het doel van deze analyse is om de gegevens op een reproduceerbare manier te verwerken en visualiseren in een RMarkdown-bestand. Hiervoor worden de volgende R-packages gebruikt: readxl voor het inlezen van de Excel-bestanden drc voor het uitvoeren van dose-response analyse ggplot2 voor het maken van grafieken Data-inlees en inspectie Om de data correct te kunnen analyseren, is het belangrijk om de stappen zorgvuldig te doorlopen. 5.1.1 Stap 1: Data opslaan en inlezen De eerste stap is om het Excel-bestand met de experimentele data op een vaste locatie op je laptop op te slaan, bijvoorbeeld in een map genaamd raw_data. Vervolgens geef je het pad naar dit bestand in R en lees je het in met behulp van de functie read_excel() uit het readxl-pakket. Als extra controle kun je de ingelezen data weergeven in een tabelvorm met behulp van de reactable-functie. Onderstaande code laat zien hoe je dit doet: # Data inlezen data_path &lt;- &quot;raw_data/CE.LIQ.FLOW.062_Tidydata.xlsx&quot; data_celegans &lt;- read_excel(data_path) # Als controle laad de data in een data tabel formaat reactable(data_celegans, defaultPageSize = 5, compact = TRUE) 5.1.2 Stap 2: Inspecteren van de datatypes In deze stap controleer je of de kolommen van de dataset correct zijn ingelezen en of ze de goede datatype hebben. Dit is belangrijk, omdat foutieve datatypes — bijvoorbeeld een getal dat als tekst is ingelezen — problemen kunnen veroorzaken in de verdere analyse. Op basis van de inhoud van de dataset wordt verwacht dat RawData zal uit numerieke waarden (numeric) bestaan, compName uit tekst (character), en compConcentration ook numeriek zal zijn. Er zijn verschillende manieren om data te inspecteren. Ik laat hieronder twee methodes zien. Manier 1: De class() functie gebruiken per kolom Met de class() functie kun je het datatype van één specifieke kolom bekijken: # Inspecteer &quot;RawData&quot; m.b.v class class(data_celegans[[&quot;RawData&quot;]]) ## [1] &quot;numeric&quot; # Inspecteer &quot;compName&quot; m.b.v class class(data_celegans[[&quot;compName&quot;]]) ## [1] &quot;character&quot; # Inspecteer &quot;compConcentration&quot; m.b.v class class(data_celegans[[&quot;compConcentration&quot;]]) ## [1] &quot;character&quot; Manier 2: Meerdere kolommen tegelijk controleren met select() en map() Bij deze methode kies je meerdere kolommen tegelijk met select() uit het dplyr-pakket. Vervolgens pas je met map() uit het purrr-pakket de functie class() toe op elke kolom, zodat je van alle geselecteerde kolommen het datatype kan bekijken. # Inspecteer de datatypes m.b.v select en map data_celegans %&gt;% dplyr::select(RawData, compName, compConcentration) %&gt;% purrr::map(class) ## $RawData ## [1] &quot;numeric&quot; ## ## $compName ## [1] &quot;character&quot; ## ## $compConcentration ## [1] &quot;character&quot; 5.1.3 Stap 3: Datatype corrigeren Uit stap twee blijkt dat de kolom compConcentration als character (tekst) is ingelezen, terwijl verwacht dat dit een numeriek datatype zou zijn. Voor een correcte analyse en visualisatie is het belangrijk dat de concentraties als getallen worden herkend. Daarom zet je deze kolom nu om naar numeriek met behulp van mutate() uit het dplyr-pakket. # Zet compConcentration om van character naar numeric data_celegans &lt;- data_celegans %&gt;% mutate(compConcentration = as.numeric(compConcentration)) # Controleer of de omzetting is gelukt class(data_celegans[[&quot;compConcentration&quot;]]) ## [1] &quot;numeric&quot; 5.1.4 Stap 4: Scatter plot maken Bij deze stap kun je een scatter plot maken m.b.v ggplot om het effect van verschillende concentraties en chemicaliën op het aantal nakomelingen van C. elegans te visualiseren. De concentratie worden op de x-as (log10-schaal) en het aantal nakomelingen (RawData) op de y-as weergegeven. Elke chemische stof krijgt een eigen kleur en de controletype (expType) wordt weergegeven met verschillende symbolen. Door jitter toe te voegen voorkom je dat punten elkaar overlappen. # Maak scatterplot data_celegans_scatterplot &lt;- ggplot(data_celegans, aes(x = compConcentration, y = RawData, color = compName, shape = expType)) + # Voeg jitter toe om overlapping van punten te voorkomen geom_jitter(width = 0.1, height = 0, alpha = 0.7, size = 2) + # Zet x-as om naar log10-schaal voor betere spreiding scale_x_log10() + # Voeg labels toe labs(x = &quot;Concentratie (log10)&quot;, y = &quot;Aantal C. elegans nakomelingen&quot;, title = &quot;Effect van chemicaliën op het aantal nakomelingen bij C. elegans&quot;, color = &quot;Compound&quot;, shape = &quot;Type meting&quot;) + # Pas thema aan voor betere leesbaarheid theme_minimal() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) # laat de scatterplot zien data_celegans_scatterplot Figuur 1: Scatterplot resultaten. Op de y-as staat het aantal nakomelingen van C. elegans en op de x-as de log10 van de compoundconcentratie. Elke compound is aangeduid met een eigen kleur en per experimenttype (controle of test) is een ander symbool gebruikt. De punten zijn licht verschoven met jitter om overlapping te voorkomen. De positieve controle voor dit experiment is ethanol, weergegeven met een driehoekig symbool. Ethanol staat bekend om zijn remmende effect op de voortplanting en wordt gebruikt om de experimentele gevoeligheid aan te tonen. De negatieve controle is S-medium, aangeduid met een cirkel, dat geen effect heeft op de voortplanting en dus de basislijn vormt voor vergelijking. Er is een duidelijke negatieve correlatie te zien tussen de compoundconcentratie en het aantal nakomelingen. Hogere concentraties leiden tot minder nakomelingen, wat suggereert dat deze stoffen toxisch zijn voor de voortplanting. Vooral bij decane en bij de hoogste concentratie van naphthalene is het aantal nakomelingen sterk verminderd. 5.1.5 Stap 5: Normalizeren van de data voor de negatieve controle Om de gevoeligheid van C. elegans voor de verschillende chemicaliën beter te kwantificeren, moet de data worden genormalizeerd. # Filter de negatieve controle control_neg &lt;- data_celegans %&gt;% filter(expType == &quot;controlNegative&quot;) # Bereken het gemiddelde van de negatieve controle control_neg_mean &lt;- mean(control_neg$RawData, na.rm = TRUE) # Check het gemiddelde van de negatieve controle control_neg_mean ## [1] 85.9 # Normaliseer de data data_celegans_normalizeren &lt;- data_celegans %&gt;% mutate(normalized_RawData = RawData / control_neg_mean) # Check of de negatieve controle correct is genormaliseerd data_celegans_normalizeren_check &lt;- data_celegans_normalizeren %&gt;% filter(expType == &quot;controlNegative&quot;) # Bereken gemiddelde van de genormaliseerde negatieve controle data_celegans_normalizeren_check_gemiddelde &lt;- mean(data_celegans_normalizeren_check$normalized_RawData) # Bekijk of het gemiddelde ongeveer 1 is data_celegans_normalizeren_check_gemiddelde ## [1] 1 Wat is normalizeren en waarom normaliseren? Dit houdt in dat de waarden voor elke stof worden uitgedrukt als een fractie van de negatieve controle, waarbij de gemiddelde waarde van de negatieve controle (S-medium) wordt ingesteld op 1. Door deze normalisatie kunnen we de effecten van de verschillende chemicaliën op de voortplanting van de wormen direct vergelijken, ongeacht de absolute schaal van de gemeten waarden. Dit helpt om de variatie tussen de verschillende experimenten te verminderen en maakt het eenvoudiger om de relatieve toxiciteit van de chemicaliën te beoordelen. Maak nu een scatterplot met de genormaliseerde waarden. # maak een scatterplot met de genormaliseerde waarden ggplot(data_celegans_normalizeren, aes(x = compConcentration, y = normalized_RawData, color = compName)) + geom_point(alpha = 0.7) + theme_minimal() + labs( title = &quot;Genormaliseerde nakomelingen per concentratie&quot;, x = &quot;Concentratie van compound&quot;, y = &quot;Genormaliseerde nakomelingen C.elegans&quot; ) + scale_x_log10() # optioneel voor log schaal Figuur 2: Genormaliseerde nakomelingen C.elegans per concentratie voor verschillende chemicaliën. Deze scatterplot met genormaliseerde waarden is duidelijk veel beter dan een plot met ruwe data. (; 5.2 Stappenplan voor dose-response analyse Een typische analyse voor dit soort data is het uitvoeren van een dose-response analyse met een log-logistisch model om de IC50 concentratie te bepalen. Je kan met de dose-response curve voor elke compound bepalen wat de effecten van de verschillende chemicaliën (ethanol, decane, naphtalene en 2,6-diisopropylnaphthalene) op het aantal nakomelingen van C.elegans. Hierbij geef ik een korte stappenplan om te helpen bij het uitvoeren van de dose-response analyse. 5.2.1 Stap 1: Installeer en laad het drc-pakket Voor deze analyse maken we gebruik van het pakket drc. Hierbij de code voor het instaleren van de pakket en vergeet niet daarna de pakket te laden. install.packages(&quot;drc&quot;) # indien nog niet geïnstalleerd library(drc) # laad de librarie 5.2.2 Stap 2: Filter de data (verwijder NA’s en incomplete observaties) Voordat we de dose-response analyse uitvoeren, is het belangrijk om te zorgen dat we enkel complete observaties gebruiken. Daarom filteren we de data en verwijderen we rijen met ontbrekende waarden (NA) in de kolommen die relevant zijn voor de analyse: de genormaliseerde respons (normalized_RawData), de concentratie (compConcentration) en de naam van de verbinding (compName). data_celegans_filter &lt;- data_celegans_normalizeren %&gt;% filter(!is.na(normalized_RawData), !is.na(compConcentration), !is.na(compName)) 5.2.3 Stap 3: Dosis-respons modellen fitten We passen per verbinding (compound) een log-logistische 4-parameter (LL.4) model toe op de gegevens. Dit model wordt vaak gebruikt om de biologische respons bij verschillende doseringen te beschrijven. Voor elke stof maken we een apart modelobject aan. # Veronderstel dat je fit objecten hebt voor elke verbinding filter_ethanol &lt;- drm(normalized_RawData ~ compConcentration, data = data_celegans_filter %&gt;% filter(compName == &quot;Ethanol&quot;), fct = LL.4()) filter_decane &lt;- drm(normalized_RawData ~ compConcentration, data = data_celegans_filter %&gt;% filter(compName == &quot;decane&quot;), fct = LL.4()) filter_naphthalene &lt;- drm(normalized_RawData ~ compConcentration, data = data_celegans_filter %&gt;% filter(compName == &quot;naphthalene&quot;), fct = LL.4()) filter_diisopropylnaphthalene &lt;- drm(normalized_RawData ~ compConcentration, data = data_celegans_filter %&gt;% filter(compName == &quot;2,6-diisopropylnaphthalene&quot;), fct = LL.4()) 5.2.4 Stap 4: Bepaal de IC50-waarden De IC50 is de concentratie waarbij de helft van het maximale effect wordt bereikt. Dit is een belangrijke maat voor toxiciteit: hoe lager de IC50, hoe toxischer de stof. Hier berekenen we de IC50 voor elke verbinding op basis van het model dat we net fitten. # Bereken IC50 voor elke verbinding IC50_ethanol &lt;- ED(filter_ethanol, 50)[1] ## ## Estimated effective doses ## ## Estimate Std. Error ## e:1:50 1.1907 NaN IC50_decane &lt;- ED(filter_decane, 50)[1] ## ## Estimated effective doses ## ## Estimate Std. Error ## e:1:50 0.119453 0.042934 IC50_naphthalene &lt;- ED(filter_naphthalene, 50)[1] ## ## Estimated effective doses ## ## Estimate Std. Error ## e:1:50 3.129 NaN IC50_diisopropylnaphthalene &lt;- ED(filter_diisopropylnaphthalene, 50)[1] ## ## Estimated effective doses ## ## Estimate Std. Error ## e:1:50 0.025072 0.010998 5.2.5 Stap 5: Overzichtstabel van IC50-waarden Hier tonen we de IC50-waarden overzichtelijk in een tabel. Dit helpt om snel te zien welke verbinding het meest toxisch is. tibble_IC50 &lt;- tibble( Compound = c(&quot;Ethanol&quot;, &quot;Decane&quot;, &quot;Naphthalene&quot;, &quot;2,6-diisopropylnaphthalene&quot;), IC50 = c(IC50_ethanol, IC50_decane, IC50_naphthalene, IC50_diisopropylnaphthalene) ) %&gt;% knitr::kable() tibble_IC50 Compound IC50 Ethanol 1.1907273 Decane 0.1194530 Naphthalene 3.1289885 2,6-diisopropylnaphthalene 0.0250723 5.2.6 Stap 6: Dosis-respons curves combineren in één figuur Hier visualiseren we de dose-response curves van alle vier verbindingen samen in één figuur. De curves geven aan hoe de respons van C. elegans verandert bij oplopende concentraties van een stof. We gebruiken een log-schaal voor de x-as en geven elke stof een unieke kleur. De legenda toont de bijbehorende IC50-waarden. # Plot eerste curve (ethanol) als basis plot( filter_ethanol, type = &quot;all&quot;, log = &quot;x&quot;, col = &quot;orange&quot;, ylim = c(0, 1.5), xlim = c(0.01, max(data_celegans_filter$compConcentration, na.rm = TRUE)), xlab = &quot;Concentratie (log)&quot;, ylab = &quot;Respons&quot;, main = &quot;Dosis-response curves&quot; ) # Voeg andere curves toe in nieuwe kleuren plot(filter_decane, add = TRUE, col = &quot;darkblue&quot;, type = &quot;all&quot;) # decane plot(filter_naphthalene, add = TRUE, col = &quot;turquoise3&quot;, type = &quot;all&quot;) # naphthalene plot(filter_diisopropylnaphthalene, add = TRUE, col = &quot;deeppink&quot;,type = &quot;all&quot;) # 2,6-diisopropylnaphthalene # Voeg legenda toe met IC50-waarden legend(&quot;topright&quot;, legend = c( paste(&quot;Ethanol:&quot;, round(IC50_ethanol, 2)), paste(&quot;Decane:&quot;, round(IC50_decane, 2)), paste(&quot;Naphthalene:&quot;, round(IC50_naphthalene, 2)), paste(&quot;2,6-diisopropylnaphthalene:&quot;, round(IC50_diisopropylnaphthalene, 2)) ), col = c(&quot;orange&quot;, &quot;darkblue&quot;, &quot;turquoise3&quot;, &quot;deeppink&quot;), lty = 1) Figuur 3: Samengestelde dosis-responscurve. In deze figuur zijn de dosis-responscurves van vier verschillende chemische verbindingen weergegeven. Op de x-as staat de logaritmische concentratie van de stof, en op de y-as de genormaliseerde respons (aantal nakomelingen van C. elegans). Elke curve toont hoe de respons verandert met toenemende concentratie. 5.2.7 Stap 7: Eén curve per stof (optioneel) Naast de gecombineerde plot kunnen we ook voor elke stof afzonderlijk de dosis-respons curve bekijken. Dit kan handig zijn voor meer gedetailleerde inspectie van de fits. # Voor ethanol plot(filter_ethanol, type = &quot;all&quot;, log = &quot;x&quot;, col = &quot;orange&quot;, main = &quot;Dose-response curve Ethanol&quot;, xlab = &quot;Concentratie&quot;, ylab = &quot;Genormaliseerde nakomelingen&quot;) Figuur 4: Dosis-responscurves (Ethanol) # Voor decane plot(filter_decane, type = &quot;all&quot;, log = &quot;x&quot;, col = &quot;darkblue&quot;, main = &quot;Dose-response curve Decane&quot;, xlab = &quot;Concentratie&quot;, ylab = &quot;Genormaliseerde nakomelingen&quot;) Figuur 5: Dosis-responscurves (Decane) # Voor naphthalene plot(filter_naphthalene, type = &quot;all&quot;, log = &quot;x&quot;, col = &quot;turquoise3&quot;, main = &quot;Dose-response curve Naphthalene&quot;, xlab = &quot;Concentratie&quot;, ylab = &quot;Genormaliseerde nakomelingen&quot;) Figuur 6: Dosis-responscurves (Naphthalene) # Voor 2,6-diisopropylnaphthalene plot(filter_diisopropylnaphthalene, type = &quot;all&quot;, log = &quot;x&quot;, col = &quot;deeppink&quot;, main = &quot;Dose-response curve 2,6-diisopropylnaphthalene&quot;, xlab = &quot;Concentratie&quot;, ylab = &quot;Genormaliseerde nakomelingen&quot;) Figuur 7: Dosis-responscurves (2,6-diisopropylnaphthalene) 5.2.8 conclusie In deze dosis-responsanalyse hebben we de IC50-waarden bepaald voor vier chemische verbindingen op basis van hun effect op C. elegans. De IC50 (de concentratie waarbij 50% van het maximale effect wordt bereikt) geeft een indicatie van de toxiciteit van een stof: hoe lager de IC50, hoe toxischer de stof is voor de wormen. Uit de resultaten blijkt het volgende: 2,6-diisopropylnaphthalene heeft de laagste IC50 (~0.025), wat wijst op een zeer hoge toxiciteit. Decane heeft ook een relatief lage IC50 (~0.12), wat duidt op matige tot hoge toxiciteit. Ethanol laat een hogere IC50 zien (~1.19), en is dus minder toxisch in vergelijking met de vorige twee. Naphthalene heeft de hoogste IC50 (~3.13), wat suggereert dat het de minst toxische stof is van de vier. Deze resultaten geven waardevolle inzicht in de relatieve toxiciteit van deze verbindingen voor C. elegans en vormen een basis voor verder toxicologisch onderzoek. 5.3 Wetenschappelijke Referenties 5.3.1 1. Ethanol en effecten op C. elegans voortplanting: Ethanol-induced reproductive toxicity in C. elegans PubMed-abstract over de effecten van ethanol op de voortplanting van C. elegans. Ethanol as a positive control for reproductive toxicity studies PubMed-abstract over ethanol als positieve controle in toxiciteitsstudies bij C. elegans. 5.3.2 2. Decaan en naphthaleen als toxische stoffen: Toxicity of aliphatic hydrocarbons, including decane Article op ScienceDirect over de toxiciteit van alifatische koolwaterstoffen, waaronder decaan. Toxicological impact of naphthalene on C. elegans PubMed-abstract over de toxische effecten van naphthaleen op C. elegans. 5.3.3 3. Dosis-responscurves en IC50-waarde bepaling: Introduction to IC50 Uitleg over IC50-bepaling en dosis-responsanalyse op NCBI. Dose-response relationship in toxicology and pharmacology PubMed-abstract over de dosis-responsrelatie in toxicologie en farmacologie. 5.3.4 4. S-medium als controle in biologische experimenten: S-medium in C. elegans experiments Artikel op SpringerLink over het gebruik van S-medium voor C. elegans-experimenten. "],["reproduceerbare-analyse-2-artikel-beoordelen-op-reproduceerbaarheid.html", "6 Reproduceerbare Analyse 2: Artikel beoordelen op reproduceerbaarheid 6.1 Artikelinformatie 6.2 Beoordeling van de reproduceerbaarheid 6.3 Reproduceerbaarheid van gedeelde R code 6.4 Conclusie", " 6 Reproduceerbare Analyse 2: Artikel beoordelen op reproduceerbaarheid In dit hoofdstuk beoordeel ik de reproduceerbaarheid van het artikel “rang: Reconstructing reproducible R computational environments” (Chan &amp; Schoch, 2023). De beoordeling vindt plaats aan de hand van vooraf gedefinieerde criteria voor transparantie, beschikbaarheid van data en code, en de uitvoerbaarheid van de gedeelde R code. 6.1 Artikelinformatie Titel: rang: Reconstructing reproducible R computational environments Referentie: Chan, C.-h. &amp; Schoch, D. (2023) PLOS ONE 18(6): e0286761. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0286761 Link naar GitHub repository met code: https://github.com/gesistsa/rang/tree/v0.3/paper 6.1.1 Onderzoeksvraag en doel van het onderzoek In dit artikel introduceren de auteurs het R-pakket rang. Dit pakket is speciaal ontwikkeld om te zorgen dat oude R-code weer uitvoerbaar wordt, ook als deze jaren geleden is geschreven. Vaak lukt het niet meer om oude analyses opnieuw uit te voeren, omdat bepaalde R-versies of pakketten niet meer bestaan of niet meer werken op moderne systemen. Het doel van het onderzoek is om een oplossing te bieden voor dat probleem, door automatisch een volledige beschrijving van de gebruikte R-omgeving te maken. Die beschrijving kan dan door andere onderzoekers gebruikt worden om de omgeving precies na te bouwen met behulp van Docker, een systeem waarmee je softwareomgevingen kunt isoleren. Met rang kunnen onderzoekers dus hun analyses delen inclusief de volledige technische context, wat zorgt voor betere reproduceerbaarheid op de lange termijn. 6.1.2 Korte samenvatting van methode en resultaten De auteurs hebben het rang-pakket ontworpen om automatisch uit te zoeken: Welke versie van R er gebruikt werd; Welke pakketten er geïnstalleerd waren (en welke versies); En hoe dit alles kan worden vastgelegd in een Dockerfile, waarmee je de oorspronkelijke omgeving later kunt reconstrueren. Ze hebben het pakket getest op verschillende oude R-projecten, waaronder code uit 2001 (!). Met behulp van rang en Docker konden ze die analyses opnieuw uitvoeren, ondanks de verouderde software. Het resultaat is een praktische tool waarmee onderzoekers zelf makkelijk een reproduceerbaar compendium kunnen maken van hun werk. Het pakket is beschikbaar via: CRAN: https://cran.r-project.org/web/packages/rang/index.html GitHub: https://github.com/chainsawriot/rang 6.2 Beoordeling van de reproduceerbaarheid In dit onderdeel bespreek ik per criterium hoe goed het artikel voldoet aan de principes van reproduceerbaar onderzoek. Daarbij kijk ik of het duidelijk is wat het doel was, of de data en code beschikbaar zijn, en of de lezer zelf het onderzoek zou kunnen herhalen. Voor de beoordeling van de reproduceerbaarheid van het artikel heb ik de criteria gebruikt uit het artikel: Wynants et al., 2020 Deze criteria omvatten onder andere: Doel van de studie Data beschikbaarheid Locatie van de data Plaats van de studie Informatie over auteurs Ethische verklaring Financiering Code beschikbaarheid Op basis hiervan is onderstaand overzicht opgesteld met een beoordeling per criterium. 6.2.1 1. Doel van de studie Beoordeling: Ja Het doel van het artikel wordt duidelijk en uitgebreid uitgelegd in de inleiding en het abstract. De auteurs willen een oplossing bieden voor een veelvoorkomend probleem in de wetenschap: analyses die na verloop van tijd niet meer reproduceerbaar zijn omdat R-pakketten, de R-versie of systeemcomponenten veranderen of niet meer beschikbaar zijn. In het abstract staat bijvoorbeeld: “A complete declarative description of the computational environment is usually missing when researchers share their materials. Without such description, software obsolescence and missing system components can jeopardize computational reproducibility in the future, even when data and computer code are available.” Het artikel stelt dit doel concreet door het introduceren van een R-pakket genaamd rang, waarmee onderzoekers een exacte, reproduceerbare kopie kunnen maken van de R-omgeving waarin analyses oorspronkelijk zijn uitgevoerd. Dit maakt het mogelijk om R-projecten, zelfs van vele jaren geleden (bijvoorbeeld uit 2001), opnieuw uit te voeren. In het artikel staat ook: “In this contribution, we show how rang can be used to make otherwise unexecutable code, spanning fields such as computational social science and bioinformatics, executable again. We also provide instructions on how to use rang to construct reproducible and shareable research compendia of current research.” Daarnaast legt het artikel uit dat het pakket werkt via containerisatie (met Docker), waardoor de volledige computational environment — inclusief het besturingssysteem, systeemcomponenten, R-versie en specifieke pakketversies — gereproduceerd kan worden. Hiermee tackelt rang de uitdagingen rondom software veroudering en het ontbreken van declaratieve omgevingsbeschrijvingen in wetenschappelijk onderzoek. Kortom, de auteurs bieden met rang een oplossing om historische R-code die anders onuitvoerbaar zou zijn, opnieuw uitvoerbaar te maken, wat een belangrijke stap is richting duurzame reproduceerbaarheid van computational research. 6.2.2 2. Data beschikbaarheid Beoordeling: Ja Het artikel vermeldt duidelijk waar de gebruikte data en code te vinden zijn. Hoewel er geen grote datasets worden gebruikt, geven de auteurs volledige toegang tot alle voorbeelddata, testscripts en analyses die in het artikel aan bod komen. In de sectie ‘Data Availability’ staat: “Data and code used in this paper are available here: https://github.com/chainsawriot/rang/tree/v0.3/paper.” De link verwijst naar een openbare GitHub-repository met zowel de broncode van het rang-pakket als de exacte code en documentatie behorend bij het artikel. Hierdoor is het mogelijk om de werkomgeving en analyses volledig te reproduceren, wat bijdraagt aan transparantie, controleerbaarheid en herbruikbaarheid van het onderzoek. Het artikel voldoet hiermee aan de principes van open science en reproduceerbare data-analyse. 6.2.3 3. Locatie van de data Beoordeling: GitHub De auteurs stellen hun data en code beschikbaar via GitHub, een veelgebruikt platform voor het delen van software en onderzoeksbestanden. In de sectie “Data Availability” staat: “Data and code used in this paper are available here: https://github.com/chainsawriot/rang/tree/v0.3/paper.” Hoewel er geen gebruik is gemaakt van een langdurig archiveringsplatform zoals Zenodo, is GitHub in de praktijk een toegankelijke en transparante manier om data en scripts te delen. De repository bevat alle benodigde bestanden om de analyses uit het artikel te reproduceren. Dit draagt bij aan de openheid en reproduceerbaarheid van het onderzoek. 6.2.4 4. Plaats van de studie Beoordeling: Ja Hoewel het artikel een software paper betreft en geen veldonderzoek beschrijft, wordt de institutionele locatie van het onderzoek duidelijk vermeld. De auteurs zijn verbonden aan: GESIS Leibniz-Institut für Sozialwissenschaften, Mannheim, Germany Deze vermelding geeft de context waarbinnen het rang-pakket is ontwikkeld en getest. Door deze expliciete vermelding voldoet het artikel aan belangrijke transparantie-eisen met betrekking tot de plaats van het onderzoek. 6.2.5 5. Informatie over auteurs Beoordeling: Ja De namen van de auteurs zijn duidelijk bovenaan het artikel vermeld en hun e-mailadressen zijn beschikbaar, wat de communicatie en verificatie vergemakkelijkt. Daarnaast zijn de ORCID-IDs opgenomen, waardoor het eenvoudiger wordt om andere publicaties van deze onderzoekers terug te vinden en hun wetenschappelijke bijdrage beter te plaatsen. Bijvoorbeeld: “Corresponding author: chung-hong.chan@gesis.org” Het artikel vermeldt de volgende auteurs en affiliaties: Chung-hong Chan [ORCID ID] David Schoch Affiliatie: GESIS Leibniz-Institut für Sozialwissenschaften, Mannheim, Germany Correspondentie e-mail: chung-hong.chan@gesis.org Daarnaast bevat het artikel standaard informatie zoals publicatiedetails, editor en copyright: Citation: Chan C-h, Schoch D (2023) rang: Reconstructing reproducible R computational environments. PLoS ONE 18(6): e0286761. https://doi.org/10.1371/journal.pone.0286761 Editor: Carlos Fernandez-Lozano, University of A Coruña, SPAIN Open Access: Het artikel valt onder een Creative Commons Attribution License, wat vrije distributie en reproductie mogelijk maakt. Deze heldere en volledige auteursinformatie draagt bij aan de transparantie en traceerbaarheid van het onderzoek. 6.2.6 6. Ethische verklaring Beoordeling: Nee (niet van toepassing) Er is geen ethische verklaring opgenomen in het artikel. Dat is logisch, want het onderzoek maakt geen gebruik van mensen, dieren of gevoelige persoonsgegevens. In software papers is een ethische verklaring meestal niet verplicht. 6.2.7 7. Financiering Beoordeling: Ja De auteurs zijn transparant over de financiering en geven duidelijk aan dat er geen specifieke financiering is ontvangen voor dit onderzoek. In het artikel staat expliciet: “The author(s) received no specific funding for this work.” Dit maakt duidelijk dat het onderzoek onafhankelijk is uitgevoerd zonder directe externe financiële steun. 6.2.8 8. Code beschikbaarheid Beoordeling: Ja De volledige broncode van het rang-pakket is beschikbaar op GitHub. Daarnaast is het pakket ook gepubliceerd op CRAN, zodat het makkelijk te installeren is. Link naar GitHub: https://github.com/gesistsa/rang De README bevat duidelijke uitleg, en de repository bevat voorbeelden, testdata en handleidingen. 6.2.9 Samenvattende tabel Criterium Beoordeling Toelichting Doel van de studie Ja Doel is duidelijk: reproduceerbare R-omgevingen met rang. Data beschikbaarheid Ja Data en code volledig beschikbaar op GitHub. Locatie van de data GitHub Data en code via GitHub, veelgebruikt maar geen archief. Plaats van de studie Ja Auteurs en affiliatie (GESIS, Mannheim) duidelijk vermeld. Informatie over auteurs Ja Namen, e-mails en ORCID-IDs beschikbaar, bevordert transparantie. Ethische verklaring Nee Niet van toepassing bij softwareonderzoek. Financiering Ja Geen specifieke financiering ontvangen, expliciet vermeld. Code beschikbaarheid Ja Code op GitHub, pakket op CRAN, met uitgebreide documentatie. 6.3 Reproduceerbaarheid van gedeelde R code De data en code zijn beschikbaar in het PLOS ONE artikel.Deze code hoort bij het maken van figuur 1 onder de kopje quanteda JOSS paper. Data: De dataset data_corpus_irishbudgets is onderdeel van het R-package quanteda.corpora. Code: De gebruikte code is gedeeld in de methodesectie van het artikel. 6.3.1 Beschrijving en beoordeling van de code De code is deze: library(&quot;quanteda&quot;) # construct the feature co-occurrence matrix examplefcm &lt;- tokens(data_corpus_irishbudget2010, remove_punct = TRUE) %&gt;% tokens_tolower() %&gt;% tokens_remove(stopwords(&quot;english&quot;), padding = FALSE) %&gt;% fcm(context = &quot;window&quot;, window = 5, tri = FALSE) # choose 30 most frequency features topfeats &lt;- names(topfeatures(examplefcm, 30)) # select the top 30 features only, plot the network set.seed(100) textplot_network(fcm_select(examplefcm, topfeats), min_freq = 0.8) 6.3.1.1 Wat doet de code? De code analyseert tekstdata uit Ierse budgettoespraken (2010) met Natural Language Processing (NLP): Preprocessing: Tekst wordt omgezet naar lowercase, stopwoorden worden verwijderd. Co-occurrentiematrix: Een netwerk van woorden die vaak samen voorkomen wordt gemaakt. Visualisatie: De 30 meest frequente woorden worden als netwerk weergegeven. 6.3.1.2 Leesbaarheid Score: 4 / 5 De code heeft een goede structuur met pipes (%&gt;%), wat de leesbaarheid vergroot. Wel ontbreken er comments die de stappen toelichten. Sommige gebruikte functies zijn verouderd, wat de duidelijkheid vermindert. 6.3.2 Reproduceerbaarheid en problemen 6.3.2.1 Problemen tijdens replicatie: Fout in datasetnaam: Oorspronkelijk: data_corpus_irishbudget2010 (werkt niet). Oplossing: Gebruik data_corpus_irishbudgets uit quanteda.corpora. Verouderde functies: topfeatures(): bestaat niet meer in quanteda 4.0. Oplossing: Vervangen door topfeatures_fcm() of eerst een DFM maken. Fout in textstat_frequency(): Werkt alleen op DFM, niet op FCM. Oplossing: Eerst dfm() toepassen voor frequentie-analyse. 6.3.3 Aangepaste code (werkt wel): library(quanteda) library(quanteda.textstats) library(quanteda.textplots) library(quanteda.corpora) # Laad het corpus data(data_corpus_irishbudgets) # Maak tokens tokens_irish &lt;- tokens(data_corpus_irishbudgets, remove_punct = TRUE) %&gt;% tokens_tolower() %&gt;% tokens_remove(stopwords(&quot;english&quot;)) # Maak een document-feature matrix (dfm) dfm_irish &lt;- dfm(tokens_irish) # Bepaal top 30 features op basis van frequentie in de dfm freq_df &lt;- textstat_frequency(dfm_irish) topfeats &lt;- freq_df$feature[1:30] # Maak feature co-occurrence matrix (fcm) met alle tokens examplefcm &lt;- fcm(tokens_irish, context = &quot;window&quot;, window = 5) # Selecteer alleen top 30 features in fcm fcm_top &lt;- fcm_select(examplefcm, pattern = topfeats) # Plot het netwerk set.seed(100) textplot_network(fcm_top, min_freq = 0.8) Figuur 1: Het codefragment dat wordt uitgevoerd in een R 3.5.1-container, is gemaakt met een bereik. De figuur toont een netwerk van de 30 meest voorkomende woorden in Ierse begrotingsspeeches, geanalyseerd met het quanteda-pakket in R. De woorden zijn geselecteerd op basis van hun frequentie en onderlinge co-occurrences binnen een venster van vijf woorden. Dikkere lijnen in het netwerk geven sterkere verbanden aan tussen woorden die vaak samen voorkomen. Uit de analyse blijkt dat de speeches sterk gericht zijn op economische thema’s. Woorden als budget, tax, economy en million komen prominent voor. Daarnaast spelen politieke termen zoals government, minister en public een grote rol, wat de nadruk op overheidsbeleid onderstreept. Sociaal-maatschappelijke onderwerpen, waaronder people, jobs en social, zijn ook veelvuldig aanwezig en suggereren een focus op werkgelegenheid en welzijn. De aanwezigheid van het woord Ireland bevestigt de nationale oriëntatie van de toespraken, terwijl termen als year en time wijzen op een jaarlijkse beleidsplanning. Deze netwerkanalyse biedt een overzicht van de centrale thema’s in de Ierse begrotingsdiscussies. Toekomstige analyses kunnen worden uitgebreid met thema’s per jaar of politieke partij, of met technieken zoals sentimentanalyse en topicmodelling voor diepgaandere inzichten (Figuur 1). 6.3.4 Beordeling op reproduceerbaarheid Reproduceerbaarheid geef ik 3/5. Code vereist aanpassingen door verouderde functies, maar met kleine wijzigingen is de figuur te reproduceren. 6.3.5 Resultaat De gereproduceerde netwerkplot ziet er vergelijkbaar uit met Figuur 1 in het artikel, maar kan verschillen door updates in packages of seed-waarden. Aanbevelingen voor betere reproduceerbaarheid: Gebruik expliciete packageversies (bijv. renv). Voeg comments toe voor context. Test code in een clean R-sessie voordat je deze deelt. 6.3.6 Evaluatie korte evluatie op de R code De analyse was reproduceerbaar na het oplossen van kleine problemen, maar het artikel had duidelijker kunnen zijn over datasetnamen en functie-updates. 6.4 Conclusie Het artikel toont goede reproduceerbaarheid dankzij volledige code- en databeschikbaarheid via GitHub/CRAN. Hoewel de R-code kleine aanpassingen vereiste (o.a. verouderde functies en datasetnamen), was de analyse succesvol te repliceren (score 3/5). Het rang-pakket biedt hiermee een praktische oplossing voor computational reproducibility, met aanbevelingen voor betere versiedocumentatie en backward compatibility. "],["structured-query-language.html", "7 Structured Query Language 7.1 Stap 1: Laad de libraries 7.2 Stap 2: Data inlezen in R 7.3 Stap 3: Data controleren. 7.4 Stap 4: Zet de data in tidy format 7.5 Stap 5: Harmoniseer landenamen 7.6 Stap 6: Voeg datasets samen 7.7 Stap 7: Zet data in een SQL-database 7.8 Stap 8: Importeer de CSV-bestanden in DBeaver 7.9 Stap 9: Inspecteer de tabellen met SQL queries 7.10 Stap 8: Voer een join uit met SQL 7.11 Stap 8: Inlezen en visualiseren in R", " 7 Structured Query Language In deze opdracht wordt gewerkt met drie verschillende datasets: gegevens over dengue, flu en de gapminder data met informatie over landen en economie. Het doel is om deze data eerst schoon te maken en ervoor te zorgen dat de landen en datums in alle datasets hetzelfde zijn. Daarna worden de datasets samengevoegd in een database met behulp van SQL. Met SQL wordt de data bekeken en gecombineerd, zodat er nieuwe verbanden te zien zijn. De resultaten worden vervolgens weer ingeladen in R om er grafieken van te maken. Deze opdracht laat zien hoe ik de verschillende databronnen kan samenbrengen en analyseren met behulp van R en SQL. 7.1 Stap 1: Laad de libraries De volgende packages zijn nodig: readr: Om csv-bestanden makkelijk in te lezen. dslabs: Bevat de gapminder dataset. stringr: Voor stringmanipulatie, zoals het aanpassen van tekstformaten. dplyr: Voor het manipuleren en schoonmaken van data tidyr: Data netjes maken: gather() (lange data), spread() (brede data), separate() (kolommen splitsen) lubridate: Datums eenvoudig verwerken: year(), month(), day() (datumdelen extraheren) ymd() (tekst → datum converteren) ggplot2: voor het maken van grafieken in R rnaturalearth: voor het ophalen van wereldkaarten en geografische data rnaturalearthdata : bevat geografische datasets die door rnaturalearth gebruikt worden sf: werkt met ‘simple features’ voor het manipuleren en visualiseren van ruimtelijke/geografische data library(readr) library(dslabs) library(stringr) library(dplyr) library(tidyr) library(lubridate) library(ggplot2) library(rnaturalearth) library(rnaturalearthdata) library(sf) 7.2 Stap 2: Data inlezen in R De datasets wordt eerst ingelezen met behulp van de functie read_csv() van het readr-package. De dengue- en flu-data bevatten enkele regels met metadata bovenaan, daarom wordt er geskippt (skip = 11) om direct bij de relevante data te beginnen. De gapminder data wordt geladen vanuit het dslabs package. # Dengue data inlezen dengue &lt;- read_csv(&quot;https://raw.githubusercontent.com/DataScienceILC/tlsc-dsfb26v-20_workflows/main/data/dengue_data.csv&quot;, skip = 11) # Flu data inlezen flu &lt;- read_csv(&quot;https://raw.githubusercontent.com/DataScienceILC/tlsc-dsfb26v-20_workflows/main/data/flu_data.csv&quot;, skip = 11) # Gapminder data inlezen vanuit dslabs package data(&quot;gapminder&quot;) # Bekijk eerste paar rijen van elke dataset head(dengue) ## # A tibble: 6 × 11 ## Date Argentina Bolivia Brazil India Indonesia Mexico Philippines ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2002-12-29 NA 0.101 0.073 0.062 0.101 NA NA ## 2 2003-01-05 NA 0.143 0.098 0.047 0.039 NA NA ## 3 2003-01-12 NA 0.176 0.119 0.051 0.059 0.071 NA ## 4 2003-01-19 NA 0.173 0.17 0.032 0.039 0.052 NA ## 5 2003-01-26 NA 0.146 0.138 0.04 0.112 0.048 NA ## 6 2003-02-02 NA 0.16 0.202 0.038 0.049 0.041 NA ## # ℹ 3 more variables: Singapore &lt;dbl&gt;, Thailand &lt;dbl&gt;, Venezuela &lt;dbl&gt; head(flu) ## # A tibble: 6 × 30 ## Date Argentina Australia Austria Belgium Bolivia Brazil Bulgaria Canada ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2002-12-29 NA NA NA NA NA 174 NA NA ## 2 2003-01-05 NA NA NA NA NA 162 NA NA ## 3 2003-01-12 NA NA NA NA NA 174 NA NA ## 4 2003-01-19 NA NA NA NA NA 162 NA NA ## 5 2003-01-26 NA NA NA NA NA 131 NA NA ## 6 2003-02-02 136 NA NA NA NA 151 NA NA ## # ℹ 21 more variables: Chile &lt;dbl&gt;, France &lt;dbl&gt;, Germany &lt;dbl&gt;, Hungary &lt;dbl&gt;, ## # Japan &lt;dbl&gt;, Mexico &lt;dbl&gt;, Netherlands &lt;dbl&gt;, `New Zealand` &lt;dbl&gt;, ## # Norway &lt;dbl&gt;, Paraguay &lt;dbl&gt;, Peru &lt;dbl&gt;, Poland &lt;dbl&gt;, Romania &lt;dbl&gt;, ## # Russia &lt;dbl&gt;, `South Africa` &lt;dbl&gt;, Spain &lt;dbl&gt;, Sweden &lt;dbl&gt;, ## # Switzerland &lt;dbl&gt;, Ukraine &lt;dbl&gt;, `United States` &lt;dbl&gt;, Uruguay &lt;dbl&gt; head(gapminder) ## country year infant_mortality life_expectancy fertility ## 1 Albania 1960 115.40 62.87 6.19 ## 2 Algeria 1960 148.20 47.50 7.65 ## 3 Angola 1960 208.00 35.98 7.32 ## 4 Antigua and Barbuda 1960 NA 62.97 4.43 ## 5 Argentina 1960 59.87 65.39 3.11 ## 6 Armenia 1960 NA 66.86 4.55 ## population gdp continent region ## 1 1636054 NA Europe Southern Europe ## 2 11124892 13828152297 Africa Northern Africa ## 3 5270844 NA Africa Middle Africa ## 4 54681 NA Americas Caribbean ## 5 20619075 108322326649 Americas South America ## 6 1867396 NA Asia Western Asia 7.3 Stap 3: Data controleren. Controle of de data in tidy format staat (elke variabele een kolom, elke observatie een rij, elke waarde een cel). # Controleer structuur van de datasets str(dengue) ## spc_tbl_ [659 × 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ Date : Date[1:659], format: &quot;2002-12-29&quot; &quot;2003-01-05&quot; ... ## $ Argentina : num [1:659] NA NA NA NA NA NA NA 0.046 0.048 0.051 ... ## $ Bolivia : num [1:659] 0.101 0.143 0.176 0.173 0.146 0.16 0.225 0.109 0.147 0.119 ... ## $ Brazil : num [1:659] 0.073 0.098 0.119 0.17 0.138 0.202 0.179 0.239 0.205 0.142 ... ## $ India : num [1:659] 0.062 0.047 0.051 0.032 0.04 0.038 0.019 0.008 0.022 0.028 ... ## $ Indonesia : num [1:659] 0.101 0.039 0.059 0.039 0.112 0.049 0.06 0.039 0.078 0.048 ... ## $ Mexico : num [1:659] NA NA 0.071 0.052 0.048 0.041 0.042 0.049 0.054 0.075 ... ## $ Philippines: num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Singapore : num [1:659] 0.059 0.059 0.238 0.175 0.164 0.163 0.15 0.144 0.142 0.129 ... ## $ Thailand : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Venezuela : num [1:659] NA NA NA NA NA NA NA 0.139 0.137 0.168 ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. Date = col_date(format = &quot;&quot;), ## .. Argentina = col_double(), ## .. Bolivia = col_double(), ## .. Brazil = col_double(), ## .. India = col_double(), ## .. Indonesia = col_double(), ## .. Mexico = col_double(), ## .. Philippines = col_double(), ## .. Singapore = col_double(), ## .. Thailand = col_double(), ## .. Venezuela = col_double() ## .. ) ## - attr(*, &quot;problems&quot;)=&lt;externalptr&gt; str(flu) ## spc_tbl_ [659 × 30] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ Date : Date[1:659], format: &quot;2002-12-29&quot; &quot;2003-01-05&quot; ... ## $ Argentina : num [1:659] NA NA NA NA NA 136 145 141 135 134 ... ## $ Australia : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Austria : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Belgium : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Bolivia : num [1:659] NA NA NA NA NA NA NA NA 426 427 ... ## $ Brazil : num [1:659] 174 162 174 162 131 151 184 162 194 177 ... ## $ Bulgaria : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Canada : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Chile : num [1:659] NA NA 1 0 0 0 0 0 0 0 ... ## $ France : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Germany : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Hungary : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Japan : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Mexico : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Netherlands : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ New Zealand : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Norway : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Paraguay : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Peru : num [1:659] 329 315 314 267 241 227 250 236 274 270 ... ## $ Poland : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Romania : num [1:659] NA NA NA NA NA NA 664 736 740 864 ... ## $ Russia : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ South Africa : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Spain : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Sweden : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Switzerland : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Ukraine : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ United States: num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## $ Uruguay : num [1:659] NA NA NA NA NA NA NA NA NA NA ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. Date = col_date(format = &quot;&quot;), ## .. Argentina = col_double(), ## .. Australia = col_double(), ## .. Austria = col_double(), ## .. Belgium = col_double(), ## .. Bolivia = col_double(), ## .. Brazil = col_double(), ## .. Bulgaria = col_double(), ## .. Canada = col_double(), ## .. Chile = col_double(), ## .. France = col_double(), ## .. Germany = col_double(), ## .. Hungary = col_double(), ## .. Japan = col_double(), ## .. Mexico = col_double(), ## .. Netherlands = col_double(), ## .. `New Zealand` = col_double(), ## .. Norway = col_double(), ## .. Paraguay = col_double(), ## .. Peru = col_double(), ## .. Poland = col_double(), ## .. Romania = col_double(), ## .. Russia = col_double(), ## .. `South Africa` = col_double(), ## .. Spain = col_double(), ## .. Sweden = col_double(), ## .. Switzerland = col_double(), ## .. Ukraine = col_double(), ## .. `United States` = col_double(), ## .. Uruguay = col_double() ## .. ) ## - attr(*, &quot;problems&quot;)=&lt;externalptr&gt; str(gapminder) ## &#39;data.frame&#39;: 10545 obs. of 9 variables: ## $ country : Factor w/ 185 levels &quot;Albania&quot;,&quot;Algeria&quot;,..: 1 2 3 4 5 6 7 8 9 10 ... ## $ year : int 1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ... ## $ infant_mortality: num 115.4 148.2 208 NA 59.9 ... ## $ life_expectancy : num 62.9 47.5 36 63 65.4 ... ## $ fertility : num 6.19 7.65 7.32 4.43 3.11 4.55 4.82 3.45 2.7 5.57 ... ## $ population : num 1636054 11124892 5270844 54681 20619075 ... ## $ gdp : num NA 1.38e+10 NA NA 1.08e+11 ... ## $ continent : Factor w/ 5 levels &quot;Africa&quot;,&quot;Americas&quot;,..: 4 1 1 2 2 3 2 5 4 3 ... ## $ region : Factor w/ 22 levels &quot;Australia and New Zealand&quot;,..: 19 11 10 2 15 21 2 1 22 21 ... # Controleer of kolomnamen en datatypes kloppen glimpse(dengue) ## Rows: 659 ## Columns: 11 ## $ Date &lt;date&gt; 2002-12-29, 2003-01-05, 2003-01-12, 2003-01-19, 2003-01-2… ## $ Argentina &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 0.046, 0.048, 0.051, 0.051, 0.… ## $ Bolivia &lt;dbl&gt; 0.101, 0.143, 0.176, 0.173, 0.146, 0.160, 0.225, 0.109, 0.… ## $ Brazil &lt;dbl&gt; 0.073, 0.098, 0.119, 0.170, 0.138, 0.202, 0.179, 0.239, 0.… ## $ India &lt;dbl&gt; 0.062, 0.047, 0.051, 0.032, 0.040, 0.038, 0.019, 0.008, 0.… ## $ Indonesia &lt;dbl&gt; 0.101, 0.039, 0.059, 0.039, 0.112, 0.049, 0.060, 0.039, 0.… ## $ Mexico &lt;dbl&gt; NA, NA, 0.071, 0.052, 0.048, 0.041, 0.042, 0.049, 0.054, 0… ## $ Philippines &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0.059,… ## $ Singapore &lt;dbl&gt; 0.059, 0.059, 0.238, 0.175, 0.164, 0.163, 0.150, 0.144, 0.… ## $ Thailand &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Venezuela &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 0.139, 0.137, 0.168, 0.169, 0.… glimpse(flu) ## Rows: 659 ## Columns: 30 ## $ Date &lt;date&gt; 2002-12-29, 2003-01-05, 2003-01-12, 2003-01-19, 2003-… ## $ Argentina &lt;dbl&gt; NA, NA, NA, NA, NA, 136, 145, 141, 135, 134, 136, 134,… ## $ Australia &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Austria &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Belgium &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Bolivia &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 426, 427, 460, 541, 54… ## $ Brazil &lt;dbl&gt; 174, 162, 174, 162, 131, 151, 184, 162, 194, 177, 223,… ## $ Bulgaria &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Canada &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Chile &lt;dbl&gt; NA, NA, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 2… ## $ France &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Germany &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Hungary &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Japan &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Mexico &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Netherlands &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `New Zealand` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Norway &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Paraguay &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Peru &lt;dbl&gt; 329, 315, 314, 267, 241, 227, 250, 236, 274, 270, 312,… ## $ Poland &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Romania &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 664, 736, 740, 864, 824, 819, … ## $ Russia &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `South Africa` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Spain &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Sweden &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Switzerland &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Ukraine &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `United States` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Uruguay &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 105, 102, … glimpse(gapminder) ## Rows: 10,545 ## Columns: 9 ## $ country &lt;fct&gt; &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Angola&quot;, &quot;Antigua and Barbuda&quot;… ## $ year &lt;int&gt; 1960, 1960, 1960, 1960, 1960, 1960, 1960, 1960, 1960,… ## $ infant_mortality &lt;dbl&gt; 115.40, 148.20, 208.00, NA, 59.87, NA, NA, 20.30, 37.… ## $ life_expectancy &lt;dbl&gt; 62.87, 47.50, 35.98, 62.97, 65.39, 66.86, 65.66, 70.8… ## $ fertility &lt;dbl&gt; 6.19, 7.65, 7.32, 4.43, 3.11, 4.55, 4.82, 3.45, 2.70,… ## $ population &lt;dbl&gt; 1636054, 11124892, 5270844, 54681, 20619075, 1867396,… ## $ gdp &lt;dbl&gt; NA, 13828152297, NA, NA, 108322326649, NA, NA, 966778… ## $ continent &lt;fct&gt; Europe, Africa, Africa, Americas, Americas, Asia, Ame… ## $ region &lt;fct&gt; Southern Europe, Northern Africa, Middle Africa, Cari… Stap 4 t/m 6: Data transformeren, harmoniseren en samenvoegen In deze stappen worden de flu- en dengue-datasets naar een tidy formaat getransformeerd, de landenamen geharmoniseerd zodat ze overeenkomen met die van de gapminder-dataset, en alle gegevens samengevoed. 7.4 Stap 4: Zet de data in tidy format De oorspronkelijke data bevat landen als kolomnamen (wide format). pivot_longer() wordt gebruikt om de data om te zetten naar long format: # Zet de data van wide naar long format: # Elke kolom met een land wordt omgezet naar een rij met bijbehorende landnaam en waarde. flu_tidy &lt;- flu %&gt;% pivot_longer(-Date, names_to = &quot;Country&quot;, values_to = &quot;Flu_rate&quot;) dengue_tidy &lt;- dengue %&gt;% pivot_longer(-Date, names_to = &quot;Country&quot;, values_to = &quot;Dengue_rate&quot;) 7.5 Stap 5: Harmoniseer landenamen De landenamen in de flu- en dengue-datasets moeten overeenkomen met de namen in gapminder. Underscores worden door spaties vervangen en in specifieke namen gecorrigeerd: # Corrigeer specifieke landenamen zodat deze overeenkomen met gapminder-data. # Underscores worden vervangen door spaties. flu_tidy &lt;- flu_tidy %&gt;% mutate(Country = case_when( Country == &quot;United_States&quot; ~ &quot;United States&quot;, Country == &quot;South_Africa&quot; ~ &quot;South Africa&quot;, TRUE ~ str_replace_all(Country, &quot;_&quot;, &quot; &quot;) )) dengue_tidy &lt;- dengue_tidy %&gt;% mutate(Country = case_when( Country == &quot;United_States&quot; ~ &quot;United States&quot;, Country == &quot;South_Africa&quot; ~ &quot;South Africa&quot;, TRUE ~ str_replace_all(Country, &quot;_&quot;, &quot; &quot;) )) 7.6 Stap 6: Voeg datasets samen Er wordt jaarkolom toegevoed, het jaargemiddelde per land berekend en deze gekoppeld aan gapminder met left_join(): # Voeg jaarkolom toe op basis van de datum flu_tidy &lt;- flu_tidy %&gt;% mutate(Year = year(Date)) dengue_tidy &lt;- dengue_tidy %&gt;% mutate(Year = year(Date)) # Bereken het jaargemiddelde per land voor griep flu_avg &lt;- flu_tidy %&gt;% group_by(Country, Year) %&gt;% summarise(Mean_Flu = mean(Flu_rate, na.rm = TRUE)) # Bereken het jaargemiddelde per land voor dengue dengue_avg &lt;- dengue_tidy %&gt;% group_by(Country, Year) %&gt;% summarise(Mean_Dengue = mean(Dengue_rate, na.rm = TRUE)) # Combineer met gapminder-data via left joins combined_data &lt;- gapminder %&gt;% left_join(flu_avg, by = c(&quot;country&quot; = &quot;Country&quot;, &quot;year&quot; = &quot;Year&quot;)) %&gt;% left_join(dengue_avg, by = c(&quot;country&quot; = &quot;Country&quot;, &quot;year&quot; = &quot;Year&quot;)) De combined_data dataset bevat nu voor elk land en jaar gegevens over bevolkingsomvang, levensverwachting, inkomen per hoofd én ziektelast door griep en dengue 7.7 Stap 7: Zet data in een SQL-database Schrijf de datasets weg naar CSV’s en gebruik DBeaver of een ander tool om deze in een PostgreSQL database te laden. # Exporteer de datasets naar CSV-bestanden voor import in DBeaver write_csv(dengue_avg, &quot;data/dengue_avg.csv&quot;) write_csv(flu_avg, &quot;data/flu_avg.csv&quot;) write_csv(gapminder, &quot;data/gapminder.csv&quot;, na = &quot;&quot;) 7.8 Stap 8: Importeer de CSV-bestanden in DBeaver Open DBeaver. Maak een nieuwe PostgreSQL database aan met de naam workflowsdb. Importeer de bestanden flu_long.csv, dengue_long.csv en gapminder_clean.csv als drie aparte tabellen: flu dengue gapminder 7.9 Stap 9: Inspecteer de tabellen met SQL queries -- Voorbeeldquery -- Bekijk de eerste 10 regels van de flu-tabel SELECT * FROM flu LIMIT 10; -- Toon unieke landen in dengue-tabel SELECT DISTINCT country FROM dengue; -- Tel aantal rijen in gapminder uit het jaar 2003 SELECT COUNT(*) FROM gapminder WHERE year = 2003; 7.10 Stap 8: Voer een join uit met SQL Nu is het mogelijk om een JOIN uit te voeren om de tabellen te combineren. Bijvoorbeeld: combineer alle drie de tabellen op country en year. -- Combineer de drie tabellen via LEFT JOIN op country en year SELECT g.country, g.year, g.life_expectancy, g.gdp, g.population, f.mean_flu, d.mean_dengue FROM gapminder g LEFT JOIN flu f ON g.country = f.country AND g.year = f.&quot;Year&quot; LEFT JOIN denguee d ON g.country = d.country AND g.year = d.&quot;Year&quot;; 7.11 Stap 8: Inlezen en visualiseren in R 7.11.1 A. visualiseer relatie tussen griep en levensverwachting # Lees samengestelde data in joined_data &lt;- read_csv(&quot;data/joined_data.csv&quot;) # Bereken de correlatie (gebruik alleen rijen zonder NA&#39;s) correlatie &lt;- cor(joined_data$mean_flu, joined_data$life_expectancy, use = &quot;complete.obs&quot;) # Maak een tekst voor in de titel cor_text &lt;- ifelse(correlatie &gt; 0, &quot;positieve&quot;, &quot;negatieve&quot;) # Visualiseer de relatie in een scatterplot ggplot(joined_data, aes(x = mean_flu, y = life_expectancy)) + geom_point(alpha = 0.7) + labs( title = paste0(&quot;Relatie tussen griep en levensverwachting (&quot;, cor_text, &quot; correlatie = &quot;, round(correlatie, 2), &quot;)&quot;), x = &quot;Gemiddelde griepratio&quot;, y = &quot;Levensverwachting&quot; ) + theme_minimal() 7.11.2 B. Lijngrafiek over tijd per land Doel: Ontwikkeling van bijvoorbeeld dengue of flu per land over de jaren. # Lijngrafiek voor dengue over tijd, per land joined_data %&gt;% filter(!is.na(mean_dengue)) %&gt;% ggplot(aes(x = year, y = mean_dengue, color = country)) + geom_line(linewidth = 1) + geom_point() + labs( title = &quot;Dengue over tijd per land&quot;, x = &quot;Jaar&quot;, y = &quot;Gemiddelde dengue-incidentie&quot; ) + theme_minimal() 7.11.3 C. Choropleth map (wereldkaart) Doel: Visueel geografisch overzicht van ziektelast of GDP. # Laad wereldkaart als sf-object world &lt;- ne_countries(scale = &quot;medium&quot;, returnclass = &quot;sf&quot;) # Voeg de epidemiologische data toe aan het kaartobject map_data &lt;- left_join(world, joined_data, by = c(&quot;name&quot; = &quot;country&quot;)) # Bereken de centroiden van de landen voor de labels map_data_centroids &lt;- st_centroid(map_data) # Plot dengue-waarden als kleuren op wereldkaart ggplot(map_data) + geom_sf(aes(fill = mean_dengue)) + geom_text(data = map_data_centroids, aes(x = st_coordinates(geometry)[,1], y = st_coordinates(geometry)[,2], label = name), size = 2, color = &quot;black&quot;, check_overlap = TRUE) + labs(title = &quot;Wereldkaart van dengue-incidentie&quot;, fill = &quot;Dengue&quot;) + theme_minimal() "],["r-package.html", "8 R package 8.1 Documentatie van mijn R package: ministate 8.2 Voorbeeld voor het gebruiken van de package", " 8 R package 8.1 Documentatie van mijn R package: ministate 8.1.1 Inleiding Dit document beschrijft de stappen die ik heb gevolgd om mijn eigen R package ministate te maken. Het doel van dit package is om eenvoudige statistische functies te bundelen in een handig en herbruikbaar pakket. Het package bevat functies voor statistische berekeningen, zoals gemiddelde, mediaan, modus, standaarddeviatie, en een overzichtelijke samenvattingstabel. 8.1.2 1. Opzetten van het project Ik heb in RStudio een nieuw R Project aangemaakt: usethis::create_package(&quot;ministate&quot;) Daarna heb ik Git gekoppeld aan mijn project: usethis::use_git() usethis::use_github() Op GitHub is de repository te vinden via: https://github.com/Amal189/ministate_package 8.1.3 2. Toevoegen van functies Ik heb 11 functies toegevoegd. Elke functie bevindt zich in een aparte .R file in de R/ map. De functies zijn voorzien van roxygen2 documentatie. 8.1.3.1 Voorbeeld: gem.R #&#39; Bereken het gemiddelde #&#39; #&#39; @param x Een numerieke vector #&#39; @return Het gemiddelde #&#39; @export gem &lt;- function(x) { mean(x, na.rm = TRUE) } Na het schrijven van de functies heb ik de documentatie gegenereerd met: devtools::document() 8.1.4 3. Testen van functies De functies zijn getest binnen RStudio: x &lt;- c(1, 2, 2, 3, NA) # Basisstatistieken gem(x) med(x) modus(x) n(x) mini(x) maxi(x) spreid(x) kwartielen(x) iqr(x) sdev(x) sam(x) 8.1.5 4. Vignette aanmaken Een vignette is een handleiding voor gebruikers. Deze heb ik aangemaakt met: usethis::use_vignette(&quot;ministate&quot;) Ik kan het vignette openen met: browseVignettes(&quot;ministate&quot;) 8.1.6 5. DESCRIPTION bestand Mijn DESCRIPTION bestand bevat de volgende informatie: Package: ministate Type: Package Title: Minianalyse van statistische functies Version: 0.1.0 Authors@R: person( given = &quot;Amal&quot;, email = &quot;Jasmijnbloem@gmail.com&quot;, role = c(&quot;aut&quot;, &quot;cre&quot;)) Description: functies voor statistische berekeningen, zoals gemiddelde, mediaan, modus, standaarddeviatie, en een overzichtelijke samenvattingstabel. License: MIT + file LICENSE Encoding: UTF-8 RoxygenNote: 7.3.2 Suggests: knitr, rmarkdown VignetteBuilder: knitr 8.1.7 6. Package bouwen en checken Voor het bouwen en controleren van mijn package gebruik ik: devtools::build() devtools::check() Let op: op Windows is het belangrijk dat Rtools is geïnstalleerd: Download hier: https://cran.r-project.org/bin/windows/Rtools/ 8.1.8 7. GitHub koppeling De koppeling met GitHub is gelukt via: git init git remote add origin https://github.com/Amal189/ministat_package.git git push -u origin master Daarna zijn alle bestanden gecommit en gepusht naar GitHub. 8.1.9 Conclusie Met dit project heb ik geleerd hoe ik een R package opzet, functies schrijf en documenteer, een vignette toevoeg, en het geheel beschikbaar maak via GitHub. Dit zijn waardevolle vaardigheden voor het delen van analyses en functies in de data science en bioinformatica wereld. 8.2 Voorbeeld voor het gebruiken van de package De faithful dataset bevat meetwaarden van eruptieduur (in minuten) van geisers in Yellowstone.Hier passen we onze functies toe op de eruptions kolom om basisstatistieken te berekenen en een overzichtstabel te maken. # Data uit R: geisers eruptie duur devtools::install_github(&quot;Amal189/ministate_package&quot;, build_vignettes = TRUE) library(ministate) data(&quot;faithful&quot;) x &lt;- faithful$eruptions # Statistieken toepassen gem(x) ## [1] 3.487783 med(x) ## [1] 4 modus(x) ## [1] 1.867 n(x) ## [1] 272 mini(x) ## [1] 1.6 maxi(x) ## [1] 5.1 spreid(x) ## [1] 3.5 kwartielen(x) ## 25% 75% ## 2.16275 4.45425 iqr(x) ## [1] 2.2915 sdev(x) ## [1] 1.141371 sam(x) "],["geparameteriseerd-covid-19-europa-rapport.html", "9 Geparameteriseerd COVID-19 Europa rapport 9.1 Geparameteriseerd data verwerken 9.2  Interactieve Quiz: Wat weet je van de COVID-data?", " 9 Geparameteriseerd COVID-19 Europa rapport 9.1 Geparameteriseerd data verwerken In dit hoofdstuk wordt het verloop van de COVID-19-pandemie geanalyseerd op basis van gegevens uit Europa. Het rapport is geparametriseerd, wat betekent dat je zelf kunt kiezen voor welk land, welk jaar en welke maand(en) je de informatie wilt bekijken. Op basis van deze keuzes worden de relevante gegevens gefilterd en weergegeven in grafieken. Er worden twee kerncijfers gevisualiseerd: Het aantal bevestigde COVID-19 gevallen per dag. Het aantal COVID-19 gerelateerde sterfgevallen per dag. Deze aanpak maakt het mogelijk om snel en flexibel inzicht te krijgen in de ontwikkeling van de pandemie binnen een specifieke context. 9.1.1 Stap 1: Laad de benodigde libraries # Laad de benodigde packages library(tidyverse) # bevat ggplot2 en dplyr library(readxl) # om Excel-bestanden te lezen library(lubridate) # voor datumverwerking indien nodig library(dplyr) library(ggplot2) library(utils) library(gganimate) library(gifski) 9.1.2 Stap 2: Download en verwerk de data De gegevens die in dit hoofdstuk worden gebruikt, zijn afkomstig van het European Centre for Disease Prevention and Control (ECDC). Deze dataset bevat dagelijkse meldingen van COVID-19 besmettingen en sterfgevallen in Europese landen. Bij het inlezen van de data worden datums correct geïnterpreteerd met behulp van het lubridate-pakket. # Download en verwerk data data &lt;- read.csv(&quot;https://opendata.ecdc.europa.eu/covid19/nationalcasedeath_eueea_daily_ei/csv&quot;, na.strings = &quot;&quot;, fileEncoding = &quot;UTF-8-BOM&quot;) %&gt;% mutate(date = dmy(dateRep), month = month(date), year = year(date)) 9.1.3 Stap 3: Foutafhandeling Om te voorkomen dat het rapport fout loopt bij ongeldige invoer, zijn er controles ingebouwd. Deze controleren of het opgegeven land, jaar en de maanden daadwerkelijk voorkomen in de dataset. # Land-validatie if (!(params$land %in% unique(data$countriesAndTerritories))) { stop(&quot;Het gekozen land komt niet voor in de dataset.&quot;) } # Jaar- en maand-validatie if (!(params$jaar %in% unique(data$year))) { stop(&quot;Het gekozen jaar komt niet voor in de dataset.&quot;) } if (!any(params$maanden %in% unique(data$month))) { stop(&quot;Geen van de gekozen maanden komt voor in de dataset.&quot;) } 9.1.4 Stap 4: Filter de data De data filteren op basis van het gekozen land, jaar en de geselecteerde maand(en). # Filteren filtered_data &lt;- data %&gt;% filter(countriesAndTerritories == params$land, year == params$jaar, month %in% params$maanden) %&gt;% arrange(date) 9.1.5 Stap 5: Het analyseren van de data De volgende grafiek toont het aantal bevestigde COVID-19 gevallen per dag in de opgegeven periode. 9.1.5.1 Aantal COVID-19 gevallen per dag Analyse voor Romania - 2020 De volgende grafieken tonen de COVID-19 data voor: Land: Romania Jaar: 2020 Maand(en): 5 # Maak een lijnplot van het aantal bevestigde gevallen per dag ggplot(filtered_data, aes(x = date, y = cases)) + geom_line(color = &quot;steelblue&quot;) + labs(title = paste(&quot;COVID-19 gevallen in&quot;, params$land, &quot;in&quot;, params$jaar), subtitle = paste(&quot;Maand(en):&quot;, paste(params$maanden, collapse = &quot;, &quot;)), x = &quot;Datum&quot;, y = &quot;Aantal gevallen&quot;) + theme_minimal() Een stijgende lijn kan wijzen op een uitbraak of onvoldoende maatregelen. Afnemende waarden kunnen wijzen op doeltreffende interventies of onderrapportage. Houd er rekening mee dat testen en rapportagebeleid per land kunnen verschillen. 9.1.5.2 Aantal COVID-19 sterfgevallen per dag De volgende grafiek toont het aantal bevestigde COVID-19 sterfgevallen per dag in de opgegeven periode.’ Analyse voor Romania - 2020 De volgende grafieken tonen de COVID-19 data voor: Land: Romania Jaar: 2020 Maand(en): 5 ggplot(filtered_data, aes(x = date, y = deaths)) + geom_line(color = &quot;#d62728&quot;) + labs(title = paste(&quot;Dagelijkse COVID-19 sterfgevallen in&quot;, params$land), subtitle = paste(&quot;Jaar:&quot;, params$jaar, &quot;| Maand(en):&quot;, paste(params$maanden, collapse = &quot;, &quot;)), x = NULL, y = &quot;Aantal sterfgevallen&quot;) + theme_minimal() + scale_x_date(date_labels = &quot;%d %b&quot;) 9.1.5.3 Beschikbaarheid van gegevens Hier bij wordt aangegeven hoeveel dagen data beschikbaar is voor de gekozen periode # Toon hoeveel dagen data beschikbaar is voor de gekozen periode paste(&quot;Aantal dagen met gegevens in deze selectie:&quot;, nrow(filtered_data)) ## [1] &quot;Aantal dagen met gegevens in deze selectie: 31&quot; 9.2  Interactieve Quiz: Wat weet je van de COVID-data? In dit onderdeel testen we je kennis van de geselecteerde gegevens. De antwoorden worden automatisch gegenereerd op basis van de data voor: Land: Romania Jaar: 2020 Maand(en): 5 9.2.1 Vraag 1: Hoeveel dagen zijn er met gegevens in deze selectie? aantal_dagen &lt;- nrow(filtered_data) paste(&quot;Aantal dagen met gegevens:&quot;, aantal_dagen) ## [1] &quot;Aantal dagen met gegevens: 31&quot; 9.2.2 Vraag 2: Hoeveel besmettingen zijn er in totaal gemeld? totaal_besmettingen &lt;- sum(filtered_data$cases, na.rm = TRUE) paste(&quot;Totaal aantal bevestigde gevallen:&quot;, totaal_besmettingen) ## [1] &quot;Totaal aantal bevestigde gevallen: 7017&quot; 9.2.3 Vraag 3: Wat was het hoogste aantal besmettingen op één dag? max_cases &lt;- max(filtered_data$cases, na.rm = TRUE) max_datum &lt;- filtered_data$date[which.max(filtered_data$cases)] paste(&quot;Hoogste aantal besmettingen op één dag:&quot;, max_cases, &quot;op&quot;, format(max_datum, &quot;%d %B %Y&quot;)) ## [1] &quot;Hoogste aantal besmettingen op één dag: 431 op 03 mei 2020&quot; 9.2.4 Vraag 4: Hoe ziet het verloop van besmettingen eruit? ggplot(filtered_data, aes(x = date, y = cases)) + geom_col(fill = &quot;steelblue&quot;) + labs(title = &quot;Besmettingen per dag&quot;, x = &quot;Datum&quot;, y = &quot;Aantal gevallen&quot;) + theme_minimal() 9.2.5 Vraag 5: Hoe ziet het verloop van sterfgevallen eruit? ggplot(filtered_data, aes(x = date, y = deaths)) + geom_col(fill = &quot;#d62728&quot;) + labs(title = &quot;Sterfgevallen per dag&quot;, x = &quot;Datum&quot;, y = &quot;Aantal overlijdens&quot;) + theme_minimal() "],["project-introductie.html", "10 Project introductie 10.1 minION sequencing", " 10 Project introductie 10.1 minION sequencing RNA-sequencing is een techniek waarmee onderzoekers kunnen meten welke genen actief zijn in een cel. De MinION-sequencer van Oxford Nanopore Technologies is een nieuwe generatie sequencingtechnologie die het mogelijk maakt om lange RNA-fragmenten in één keer te lezen (Jain et al. 2016). In dit project wordt RNA-sequencing data van MCF7-borstkankercellen geanalyseerd. Het doel is om de kwaliteit van de data te beoordelen en om te onderzoeken of deze geschikt is voor het analyseren van genexpressie. Traditionele RNA-sequencing methoden, zoals die van Illumina, produceren korte reads die vaak onvoldoende informatie geven over volledige RNA-transcripten (Wang, Gerstein, and Snyder 2009). Lange reads van de MinION maken het mogelijk om complete genvarianten te identificeren, wat nuttig is bij onderzoek naar alternatieve splicing en genexpressie (Byrne 2017). Omdat de foutenmarge van de MinION hoger is dan bij short-read technologieën, is kwaliteitscontrole een belangrijke eerste stap (De Coster et al. 2018). Voor deze analyse wordt gebruikgemaakt van openbare data die eerder is gegenereerd door Chen et al. (2021), waarin RNA uit MCF7-cellen is gesekveneerd met de MinION (Chen, Zhang, and Zhu 2021). De workflow begint met kwaliteitscontrole van de ruwe sequencing data met behulp van NanoFilt en NanoPlot (De Coster et al. 2018). Vervolgens worden de RNA-reads uitgelijnd op het humane genoom met Minimap2, een aligner die geschikt is voor lange reads en splicing-herkenning (Li 2018). Daarna wordt het expressieniveau van genen bepaald met behulp van Bambu, een tool die ontworpen is voor transcriptidentificatie en kwantificatie in long-read RNA-seq data (Kaminow, Yanai, and Gresham 2021). De differentiële genexpressie wordt geanalyseerd met DESeq2, een veelgebruikte methode binnen de bioinformatica (Love, Huber, and Anders 2014). Tot slot worden de resultaten gevisualiseerd met PCA-plots, heatmaps en scatterplots. Deze visualisaties geven inzicht in verschillen in genexpressie en in de bruikbaarheid van lange-read sequencing data bij transcriptomics-onderzoek. Figuur 1: Workflow voor RNA-seq data-analyse. De onderstaande figuur toont een overzicht van een typische workflow voor de analyse van RNA-sequencing (RNA-seq) data, zoals uitgevoerd in dit project. Deze workflow is gebaseerd op het materiaal uit de cursus Data Science for Biology 1 (DSFB1). "],["referenties.html", "11 Referenties", " 11 Referenties Byrne, Andrew et al. 2017. “Nanopore Long-Read RNAseq Reveals Widespread Transcriptional Variation Among the Surface Receptors of Individual b Cells.” Nature Communications 8 (1): 16027. https://doi.org/10.1038/ncomms16027. Chen, X, Y Zhang, and Z Zhu. 2021. “High-Throughput Long-Read RNA Sequencing of Human Transcriptomes with eCLIP.” Nature Biotechnology 39 (7): 750–60. https://doi.org/10.1038/s41587-020-00791-4. De Coster, Wouter, Sophie D’Hert, David T Schultz, Marc Cruts, and Christine Van Broeckhoven. 2018. “NanoPack: Visualizing and Processing Long-Read Sequencing Data.” Bioinformatics 34 (15): 2666–69. https://doi.org/10.1093/bioinformatics/bty149. Jain, Miten, Heather E Olsen, Benedict Paten, and Mark Akeson. 2016. “The Oxford Nanopore MinION: Delivery of Nanopore Sequencing to the Genomics Community.” Genome Biology 17 (1): 1–11. https://doi.org/10.1186/s13059-016-1103-0. Kaminow, Brennan, Itai Yanai, and David Gresham. 2021. “Bambu: Transcript Discovery and Quantification from Long-Read RNA-Seq Data.” Genome Biology 22 (1): 1–24. https://doi.org/10.1186/s13059-021-02507-3. Li, Heng. 2018. “Minimap2: Pairwise Alignment for Nucleotide Sequences.” Bioinformatics 34 (18): 3094–3100. https://doi.org/10.1093/bioinformatics/bty191. Love, Michael I, Wolfgang Huber, and Simon Anders. 2014. “Moderated Estimation of Fold Change and Dispersion for RNA-Seq Data with DESeq2.” Genome Biology 15 (12): 550. https://doi.org/10.1186/s13059-014-0550-8. Wang, Zhong, Mark Gerstein, and Michael Snyder. 2009. “RNA-Seq: A Revolutionary Tool for Transcriptomics.” Nature Reviews Genetics 10 (1): 57–63. https://doi.org/10.1038/nrg2484. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
